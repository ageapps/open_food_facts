{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN FOOD NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import folium\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "\n",
    "#from google.cloud import translate\n",
    "#import pycountry\n",
    "#import emoji\n",
    "\n",
    "#translate_client = translate.Client()\n",
    "\n",
    "from py_translator import Translator\n",
    "# from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a data folder where the .csv file will be stored and also a maps folder where .html maps will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "maps_folder = './maps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'en.openfoodfacts.org.products.csv'\n",
    "countryfile = 'wikipedia-iso-country-codes.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_col = [\n",
    "    \"product_name\",\n",
    "    \"generic_name\",\n",
    "    \"quantity\",\n",
    "    \"brands\",\n",
    "    \"brands_tags\",\n",
    "    \"categories\",\n",
    "    \"categories_tags\",\n",
    "    \"categories_en\",\n",
    "    \"manufacturing_places\",\n",
    "    \"manufacturing_places_tags\",\n",
    "    \"labels\",\n",
    "    \"labels_tags\",\n",
    "    \"labels_en\",\n",
    "    \"purchase_places\",\n",
    "    \"countries\",\n",
    "    \"countries_tags\",\n",
    "    \"countries_en\",\n",
    "    \"ingredients_text\",\n",
    "    \"allergens\",\n",
    "    \"allergens_en\",\n",
    "    \"traces\",\n",
    "    \"traces_tags\",\n",
    "    \"traces_en\",\n",
    "    \"nutrition_grade_uk\",\n",
    "    \"nutrition_grade_fr\",\n",
    "    \"main_category\",\n",
    "    \"main_category_en\",\n",
    "    \"energy_100g\",\n",
    "    \"energy-from-fat_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"trans-fat_100g\",\n",
    "    \"cholesterol_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\",\n",
    "    \"alcohol_100g\",\n",
    "    \"calcium_100g\",\n",
    "    \"iron_100g\",\n",
    "    \"carbon-footprint_100g\",\n",
    "    \"nutrition-score-fr_100g\",\n",
    "    \"nutrition-score-uk_100g\",\n",
    "    \"glycemic-index_100g\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_df = pd.read_csv(data_folder + filename, \n",
    "                      sep='\\t',\n",
    "                      header=0,\n",
    "                      usecols = using_col,\n",
    "                      quotechar='\"', \n",
    "                      low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of the data set are: \n",
      " product_name                  object\n",
      "generic_name                  object\n",
      "quantity                      object\n",
      "brands                        object\n",
      "brands_tags                   object\n",
      "categories                    object\n",
      "categories_tags               object\n",
      "categories_en                 object\n",
      "manufacturing_places          object\n",
      "manufacturing_places_tags     object\n",
      "labels                        object\n",
      "labels_tags                   object\n",
      "labels_en                     object\n",
      "purchase_places               object\n",
      "countries                     object\n",
      "countries_tags                object\n",
      "countries_en                  object\n",
      "ingredients_text              object\n",
      "allergens                     object\n",
      "allergens_en                  object\n",
      "traces                        object\n",
      "traces_tags                   object\n",
      "traces_en                     object\n",
      "nutrition_grade_uk           float64\n",
      "nutrition_grade_fr            object\n",
      "main_category                 object\n",
      "main_category_en              object\n",
      "energy_100g                  float64\n",
      "energy-from-fat_100g         float64\n",
      "fat_100g                     float64\n",
      "saturated-fat_100g           float64\n",
      "trans-fat_100g               float64\n",
      "cholesterol_100g             float64\n",
      "carbohydrates_100g           float64\n",
      "sugars_100g                  float64\n",
      "fiber_100g                   float64\n",
      "proteins_100g                float64\n",
      "salt_100g                    float64\n",
      "sodium_100g                  float64\n",
      "alcohol_100g                 float64\n",
      "calcium_100g                 float64\n",
      "iron_100g                    float64\n",
      "carbon-footprint_100g        float64\n",
      "nutrition-score-fr_100g      float64\n",
      "nutrition-score-uk_100g      float64\n",
      "glycemic-index_100g          float64\n",
      "dtype: object\n",
      "The total size of the data set is: (693984, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>manufacturing_places</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vit√≥ria crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130 g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendiants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salade de carottes r√¢p√©es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_name generic_name quantity brands brands_tags  \\\n",
       "0           Vit√≥ria crackers          NaN      NaN    NaN         NaN   \n",
       "1                      Cacao          NaN    130 g    NaN         NaN   \n",
       "2      Sauce Sweety chili 0%          NaN      NaN    NaN         NaN   \n",
       "3                  Mendiants          NaN      NaN    NaN         NaN   \n",
       "4  Salade de carottes r√¢p√©es          NaN      NaN    NaN         NaN   \n",
       "\n",
       "  categories categories_tags categories_en manufacturing_places  \\\n",
       "0        NaN             NaN           NaN                  NaN   \n",
       "1        NaN             NaN           NaN                  NaN   \n",
       "2        NaN             NaN           NaN                  NaN   \n",
       "3        NaN             NaN           NaN                  NaN   \n",
       "4        NaN             NaN           NaN                  NaN   \n",
       "\n",
       "  manufacturing_places_tags         ...         proteins_100g salt_100g  \\\n",
       "0                       NaN         ...                   7.8      1.40   \n",
       "1                       NaN         ...                   NaN       NaN   \n",
       "2                       NaN         ...                   0.2      2.04   \n",
       "3                       NaN         ...                   NaN       NaN   \n",
       "4                       NaN         ...                   0.9      0.42   \n",
       "\n",
       "  sodium_100g alcohol_100g calcium_100g iron_100g carbon-footprint_100g  \\\n",
       "0    0.551181          NaN          NaN       NaN                   NaN   \n",
       "1         NaN          NaN          NaN       NaN                   NaN   \n",
       "2    0.803150          NaN          NaN       NaN                   NaN   \n",
       "3         NaN          NaN          NaN       NaN                   NaN   \n",
       "4    0.165354          NaN          NaN       NaN                   NaN   \n",
       "\n",
       "  nutrition-score-fr_100g nutrition-score-uk_100g glycemic-index_100g  \n",
       "0                     NaN                     NaN                 NaN  \n",
       "1                     NaN                     NaN                 NaN  \n",
       "2                     NaN                     NaN                 NaN  \n",
       "3                     NaN                     NaN                 NaN  \n",
       "4                     NaN                     NaN                 NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The types of the data set are: \\n\", format(food_df.dtypes))\n",
    "print (\"The total size of the data set is:\", format(food_df.shape) )\n",
    "food_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing product_name\n",
    "This section deals with NaN values for `product_name`. If it does not have a `product_name`, the `generic_name` was used. If neither field was filled, then a combination of `brands` and `categories_en`/`main_category` was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name: 25881\n"
     ]
    }
   ],
   "source": [
    "# remove rows where the columns we are interested in are all null\n",
    "food_df = food_df.dropna(subset=using_col, how='all')\n",
    "\n",
    "print(\"Number of rows w/missing product_name: {}\".format(len(food_df) - food_df['product_name'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    if pd.isnull(row['product_name']):\n",
    "        if pd.isnull(row['generic_name']):\n",
    "            if pd.isnull(row['main_category_en']) & pd.isnull(row['categories_en']) & pd.isnull(row['brands']):\n",
    "                return\n",
    "            else:\n",
    "                category_name = row['main_category_en']\n",
    "                if pd.isnull(category_name):\n",
    "                    category_name = row['categories_en']\n",
    "                return \"{} {}\".format(row['brands'], category_name)\n",
    "        else:\n",
    "            return row['generic_name']\n",
    "    else:\n",
    "        return row['product_name']\n",
    "    \n",
    "df = food_df.copy()\n",
    "\n",
    "df['product_name'] = df.apply(\n",
    "    lambda x: get_name(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name after modifications: 22458\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing product_name after modifications: {}\".format(len(df) - df['product_name'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns that we no longer need\n",
    "used_col = [\n",
    "    'generic_name',\n",
    "    'main_category',\n",
    "    'main_category_en',\n",
    "    'brands',\n",
    "    'brands_tags',\n",
    "    'categories',\n",
    "    'categories_tags',\n",
    "    'categories_en',\n",
    "]\n",
    "\n",
    "df = df.drop(used_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Values for Country\n",
    "This section deals with the missing values for `countries_en`. The `countries_en` column represents the countries where the product is sold. This column is important for our analysis because we want to analyze how viable it is to live in each country based off one's dietary restrictions.\n",
    "\n",
    "In order to fix these missing values, we decided to first fill the column with values from `purchase_places`, then `manufacturing_places`. We decided to use `purchase_places` because if it was purchased in a certain country, obviously it means the product is sold there as well. As for `manufacturing_places`, we assumed that it is most likely that a product manufactured in a country would be sold there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 459\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df) - df['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_country(row):\n",
    "    if pd.isnull(row['countries_en']):\n",
    "        alt_country = None\n",
    "        if pd.notna(row['purchase_places']):\n",
    "            alt_country = row['purchase_places']\n",
    "        elif pd.notna(row['manufacturing_places']):\n",
    "            alt_country = row['manufacturing_places']\n",
    "            \n",
    "        # got value from purchase_places or manufacturing_places\n",
    "        if (not alt_country is None) and pd.notna(alt_country):\n",
    "            translator = Translator()\n",
    "            try:\n",
    "                en_alt_country = translator.translate(text=alt_country, dest='en')\n",
    "                if not en_alt_country is None:\n",
    "                    return en_alt_country.text\n",
    "            except Exception as e:\n",
    "                return alt_country\n",
    "            \n",
    "        return alt_country\n",
    "    else:\n",
    "        return row['countries_en']\n",
    "    \n",
    "df_1 = df.copy()\n",
    "\n",
    "df_1['countries_en'] = df_1.apply(\n",
    "    lambda x: translate_country(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 322\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df_1) - df_1['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/multiple countries: 28626\n",
      "Number of total rows: 693524\n"
     ]
    }
   ],
   "source": [
    "# drop rows without country\n",
    "df_1 = df_1.dropna(subset=['countries_en'])\n",
    "\n",
    "\n",
    "print(\"Number of rows w/multiple countries: {}\".format(\n",
    "    len(df_1[df_1['countries_en'].str.contains(',')])))\n",
    "\n",
    "print(\"Number of total rows: {}\".format(len(df_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are no longer needed\n",
    "used_col = [\n",
    "    'purchase_places',\n",
    "    'manufacturing_places',\n",
    "    'manufacturing_places_tags',\n",
    "    'countries_tags',\n",
    "    'countries',\n",
    "]\n",
    "\n",
    "df_1 = df_1.drop(used_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries_en</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Lion Peanut x2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Moelleux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Pack de 2 Twix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>France,United States</td>\n",
       "      <td>Root Beer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>France,Germany</td>\n",
       "      <td>Fuzetea schwarzer Tee Zitrone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             countries_en                   product_name\n",
       "173  France,United States                 Lion Peanut x2\n",
       "196  France,United States                       Moelleux\n",
       "205  France,United States                 Pack de 2 Twix\n",
       "290  France,United States                      Root Beer\n",
       "426        France,Germany  Fuzetea schwarzer Tee Zitrone"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that some countries_en are lists\n",
    "df_1[df_1['countries_en'].notnull() & df_1['countries_en'].str.contains(',')][['countries_en', 'product_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the list substring into an array\n",
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2['countries_en'] = df_2.apply(\n",
    "    lambda x: [x.strip() for x in x['countries_en'].split(',')],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# [x.strip() for x in my_string.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>countries_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>[France, United States]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_name             countries_en\n",
       "173  Lion Peanut x2  [France, United States]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that the countries has been properly split\n",
    "df_2[df_2.index == 173][['product_name', 'countries_en']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this subsection deals with standardizing the countries for each product. First, we notice that some products have more than one country in their `countries_en` field. In this case, we seperate/explode each country in the `countries_en` field so that each country has its own row for that item. Next, we join the countries with their respective country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>√•land islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country_name country_code\n",
       "0     afghanistan           AF\n",
       "1   √•land islands           AX\n",
       "2         albania           AL\n",
       "3         algeria           DZ\n",
       "4  american samoa           AS"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the countries_en to country codes\n",
    "country_df = pd.read_csv(data_folder + countryfile, \n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         usecols=['English short name lower case', 'Alpha-2 code'],\n",
    "                         quotechar='\"')\n",
    "# rename columns\n",
    "country_df.rename(columns={\n",
    "    'Alpha-2 code':'country_code',\n",
    "    'English short name lower case': 'country_name'\n",
    "    }, inplace=True)\n",
    "\n",
    "# country_df['country_name'] = country_df.apply(\n",
    "#     lambda x: x['country_name'].split(',')[0] if ',' in x['country_name'] else x['country_name'],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "country_df['country_name'] = country_df.apply(\n",
    "    lambda x: x['country_name'].lower(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]\n",
    "\n",
    "df_3 = df_2.copy()\n",
    "df_3 = explode(df_3,'countries_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_tags</th>\n",
       "      <th>labels_en</th>\n",
       "      <th>countries_en</th>\n",
       "      <th>ingredients_text</th>\n",
       "      <th>allergens</th>\n",
       "      <th>allergens_en</th>\n",
       "      <th>traces</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_name quantity labels labels_tags labels_en   countries_en  \\\n",
       "173  Lion Peanut x2      NaN    NaN         NaN       NaN         France   \n",
       "174  Lion Peanut x2      NaN    NaN         NaN       NaN  United States   \n",
       "\n",
       "    ingredients_text allergens allergens_en traces         ...           \\\n",
       "173              NaN       NaN          NaN    NaN         ...            \n",
       "174              NaN       NaN          NaN    NaN         ...            \n",
       "\n",
       "    proteins_100g salt_100g  sodium_100g alcohol_100g  calcium_100g  \\\n",
       "173           NaN       NaN          NaN          NaN           NaN   \n",
       "174           NaN       NaN          NaN          NaN           NaN   \n",
       "\n",
       "     iron_100g  carbon-footprint_100g  nutrition-score-fr_100g  \\\n",
       "173        NaN                    NaN                      NaN   \n",
       "174        NaN                    NaN                      NaN   \n",
       "\n",
       "     nutrition-score-uk_100g  glycemic-index_100g  \n",
       "173                      NaN                  NaN  \n",
       "174                      NaN                  NaN  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how the explode function created another row because there were two countries for Lion Peanut x2\n",
    "df_3[df_3['product_name'].notna() & df_3['product_name'].str.contains('Lion Peanut x2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "# rename countries_en to country_name\n",
    "df_4.rename(columns={'countries_en':'country_name'}, inplace=True)\n",
    "\n",
    "df_4['country_name'] = df_4.apply(\n",
    "    lambda x: x['country_name'].lower(),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notAssigned(df_sample):\n",
    "    not_assigned = df_sample[df_sample['country_name'].notna() & df_sample['country_code'].isna()]\n",
    "\n",
    "    print(\"Number of unassigned items is: {}\".format(len(not_assigned)))\n",
    "    print(\"The important values are: \")\n",
    "    print(not_assigned['country_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unassigned items is: 4566\n",
      "The important values are: \n",
      "russia                                                                                2203\n",
      "en                                                                                     477\n",
      "fr:deutschland                                                                         229\n",
      "taiwan                                                                                 227\n",
      "vietnam                                                                                107\n",
      "de:allemagne                                                                            92\n",
      "ch:suisse                                                                               82\n",
      "european union                                                                          80\n",
      "south korea                                                                             67\n",
      "fr:schweiz                                                                              49\n",
      "republic of macedonia                                                                   41\n",
      "fr:frankreich                                                                           35\n",
      "product name completed                                                                  34\n",
      "categories completed                                                                    34\n",
      "brands completed                                                                        34\n",
      "quantity completed                                                                      33\n",
      "packaging completed                                                                     33\n",
      "photos uploaded                                                                         33\n",
      "nutrition facts completed                                                               33\n",
      "characteristics completed                                                               33\n",
      "ingredients completed                                                                   33\n",
      "photos validated                                                                        30\n",
      "to be checked                                                                           30\n",
      "complete                                                                                30\n",
      "packaging-code-completed                                                                26\n",
      "fr:dom-tom                                                                              24\n",
      "fr:quebec                                                                               24\n",
      "iran                                                                                    24\n",
      "democratic republic of the congo                                                        24\n",
      "kosovo                                                                                  21\n",
      "                                                                                      ... \n",
      "san miguel de allende                                                                    1\n",
      "seine-maritime                                                                           1\n",
      "virgin islands of the united states                                                      1\n",
      "ingredients to be completed                                                              1\n",
      "plane                                                                                    1\n",
      "washington                                                                               1\n",
      "sydney                                                                                   1\n",
      "characteristics to be completed                                                          1\n",
      "fr:quebec-canada                                                                         1\n",
      "cluj-napoca                                                                              1\n",
      "nutrition facts to be completed                                                          1\n",
      "de:belgique                                                                              1\n",
      "roumanie                                                                                 1\n",
      "champs fleurs                                                                            1\n",
      "s√£o paulo-sp brasil                                                                      1\n",
      "m√ºnchen                                                                                  1\n",
      "packaging to be completed                                                                1\n",
      "guanajuato                                                                               1\n",
      "√©tats-unis                                                                               1\n",
      "navarra                                                                                  1\n",
      "tunisie                                                                                  1\n",
      "w.i.                                                                                     1\n",
      "danone produits frais france (dpff) - route de savignies - 76220 ferri√®res-en-bray       1\n",
      "guerrero                                                                                 1\n",
      "arm√©nie                                                                                  1\n",
      "photos to be uploaded                                                                    1\n",
      "frankfurt                                                                                1\n",
      "bannans                                                                                  1\n",
      "republika srpska                                                                         1\n",
      "luxemburgo                                                                               1\n",
      "Name: country_name, Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_5 = df_4.copy()\n",
    "\n",
    "df_5 = df_5.merge(country_df, how='left')\n",
    "    \n",
    "notAssigned(df_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to fix the country codes with the highest frequency, since the importance/effect of fixing the lower values will decrease as we descend through the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Russian Federation to russia\n",
    "country_df['country_name'][country_df['country_code'] == 'RU'] = 'russia'\n",
    "\n",
    "# changing Korea, Republic of to south korea\n",
    "country_df['country_name'][country_df['country_code'] == 'KR'] = 'south korea'\n",
    "\n",
    "# changing Macedonia, the former Yugoslav Republic of to republic of macedonia\n",
    "country_df['country_name'][country_df['country_code'] == 'MK'] = 'republic of macedonia'\n",
    "\n",
    "# changing Taiwan, Province of China to taiwan\n",
    "country_df['country_name'][country_df['country_code'] == 'TW'] = 'taiwan'\n",
    "\n",
    "# changing Viet Nam to vietnam\n",
    "country_df['country_name'][country_df['country_code'] == 'VN'] = 'vietnam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "\n",
    "def parseTranslate(x):\n",
    "    if (':') in x['country_name']:\n",
    "        info_ = x['country_name'].split(':')\n",
    "        if len(info_) == 2:\n",
    "            try:\n",
    "                translate_country = translator.translate(text=info_[1], dest='en').text\n",
    "                return translate_country.lower()\n",
    "            except Exception:\n",
    "                return info_[1]\n",
    "        \n",
    "    return x['country_name']\n",
    "\n",
    "df_6 = df_4.copy()\n",
    "\n",
    "df_6['country_name'] = df_6.apply(\n",
    "    lambda x: parseTranslate(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palestinian territories\n",
      "argentina\n",
      "moldova, republic of\n",
      "argentina\n",
      "argentina\n",
      "m√©xico\n",
      "argentina\n",
      "argentina\n",
      "saint martin (french part)\n",
      "european union\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "saint martin (french part)\n",
      "the bahamas\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "united-states-of-america\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "washington\n",
      "usa\n",
      "european union\n",
      "quebec\n",
      "quebec\n",
      "quebec\n",
      "montr√©al\n",
      "argentina\n",
      "quebec\n",
      "quebec\n",
      "quebec-canada\n",
      "argentina\n",
      "quebec\n",
      "allemagne\n",
      "weil am rhein\n",
      "argentina\n",
      "argentina\n",
      "cura√ßao\n",
      "quebec\n",
      "argentina\n",
      "cura√ßao\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "√©tats-unis\n",
      "argentina\n",
      "european union\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "quebec\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "suisse\n",
      "england\n",
      "quebec\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "u salumu\n",
      "european union\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "laos\n",
      "european union\n",
      "quebec\n",
      "argentina\n",
      "r√©publique dominicaine\n",
      "democratic republic of the congo\n",
      "venezuela, bolivarian republic of\n",
      "quebec\n",
      "california\n",
      "usa\n",
      "quebec\n",
      "perth\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "venezuela, bolivarian republic of\n",
      "the bahamas\n",
      "iran, islamic republic of\n",
      "argentina\n",
      "argentina\n",
      "argentina\n",
      "virgin islands of the united states\n",
      "san miguel de allende\n",
      "guanajuato\n",
      "argentina\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-3a280e4c585b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m df_6['country_name'] = df_6.apply(\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                           \u001b[0mdummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m                                           labels=labels)\n\u001b[0m\u001b[1;32m    243\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.reduce\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.Reducer.get_result\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-3a280e4c585b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m df_6['country_name'] = df_6.apply(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-26-54f9d66b0f3f>\u001b[0m in \u001b[0;36mbest_match\u001b[0;34m(country_df, row)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mcountries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ada2/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mdtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;31m# ndarray compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;34m\"\"\" return the dtype object of the underlying data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_6 = df_6.merge(country_df, how='left')\n",
    "\n",
    "df_6['country_name'] = df_6.apply(\n",
    "    lambda x: best_match(country_df, x),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "df_6 = df_6.merge(country_df, how='left')\n",
    "\n",
    "notAssigned(df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
