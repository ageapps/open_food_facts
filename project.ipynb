{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN FOOD NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import folium\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#from google.cloud import translate\n",
    "#import pycountry\n",
    "#import emoji\n",
    "\n",
    "#translate_client = translate.Client()\n",
    "\n",
    "import sys # for printing process\n",
    "import unidecode # for normalizing text\n",
    "from pathlib import Path # check files\n",
    "\n",
    "\n",
    "from py_translator import Translator\n",
    "translator = Translator()\n",
    "\n",
    "# from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE HAD DIFFICULTIES MERGING, FATS CLEANING IS IN `project_fats` FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a data folder where the .csv file will be stored and also a maps folder where .html maps will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'en.openfoodfacts.org.products.csv'\n",
    "countryfile = 'wikipedia-iso-country-codes.csv'\n",
    "translationsfile = 'translations.csv'\n",
    "foodfile = 'food.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_col = [\n",
    "    \"product_name\",\n",
    "    \"generic_name\",\n",
    "    \"quantity\",\n",
    "    \"brands\",\n",
    "    \"brands_tags\",\n",
    "    \"categories\",\n",
    "    \"categories_tags\",\n",
    "    \"categories_en\",\n",
    "    \"manufacturing_places\",\n",
    "    \"manufacturing_places_tags\",\n",
    "    \"labels\",\n",
    "    \"labels_tags\",\n",
    "    \"labels_en\",\n",
    "    \"purchase_places\",\n",
    "    \"countries\",\n",
    "    \"countries_tags\",\n",
    "    \"countries_en\",\n",
    "    \"ingredients_text\",\n",
    "    \"allergens\",\n",
    "    \"allergens_en\",\n",
    "    \"traces\",\n",
    "    \"traces_tags\",\n",
    "    \"traces_en\",\n",
    "    \"nutrition_grade_uk\",\n",
    "    \"nutrition_grade_fr\",\n",
    "    \"main_category\",\n",
    "    \"main_category_en\",\n",
    "    \"energy_100g\",\n",
    "    \"energy-from-fat_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"trans-fat_100g\",\n",
    "    \"cholesterol_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\",\n",
    "    \"alcohol_100g\",\n",
    "    \"calcium_100g\",\n",
    "    \"iron_100g\",\n",
    "    \"carbon-footprint_100g\",\n",
    "    \"nutrition-score-fr_100g\",\n",
    "    \"nutrition-score-uk_100g\",\n",
    "    \"glycemic-index_100g\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# unknown values to use\n",
    "UNKNOWN_NR='-1'\n",
    "UNKNOWN_STR='unknown'\n",
    "# delay between translation requests\n",
    "TRANSLATION_DELAY=0.3\n",
    "# progress in function\n",
    "PROGRESS=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations file found\n",
      "3026 translations found\n"
     ]
    }
   ],
   "source": [
    "# cache translations to save translation requests\n",
    "translations_file = Path(data_folder + translationsfile)\n",
    "translations = {}\n",
    "\n",
    "if not translations_file.is_file():\n",
    "    print('Translations file not found')\n",
    "else:\n",
    "    print('Translations file found')\n",
    "    translations = pd.read_csv(data_folder + translationsfile, \n",
    "                               sep='\\t',\n",
    "                               low_memory=False).to_dict(\"records\")[0]\n",
    "    print('{} translations found'.format(len(translations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_file = Path(data_folder + foodfile)\n",
    "food_df = pd.DataFrame()\n",
    "\n",
    "if not food_file.is_file():\n",
    "    print('Food file not found')\n",
    "    food_df = pd.read_csv(data_folder + filename, \n",
    "                      sep='\\t',\n",
    "                      header=0,\n",
    "                      usecols = using_col,\n",
    "                      quotechar='\"', \n",
    "                      low_memory=False)\n",
    "else:\n",
    "    print('Food file found')\n",
    "    food_df = pd.read_csv(data_folder + foodfile, \n",
    "                      sep='\\t',\n",
    "                      low_memory=False)\n",
    "    print('{} Food entries found'.format(len(food_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of the data set are: \n",
      " product_name                  object\n",
      "generic_name                  object\n",
      "quantity                      object\n",
      "brands                        object\n",
      "brands_tags                   object\n",
      "categories                    object\n",
      "categories_tags               object\n",
      "categories_en                 object\n",
      "manufacturing_places          object\n",
      "manufacturing_places_tags     object\n",
      "labels                        object\n",
      "labels_tags                   object\n",
      "labels_en                     object\n",
      "purchase_places               object\n",
      "countries                     object\n",
      "countries_tags                object\n",
      "countries_en                  object\n",
      "ingredients_text              object\n",
      "allergens                     object\n",
      "allergens_en                  object\n",
      "traces                        object\n",
      "traces_tags                   object\n",
      "traces_en                     object\n",
      "nutrition_grade_uk           float64\n",
      "nutrition_grade_fr            object\n",
      "main_category                 object\n",
      "main_category_en              object\n",
      "energy_100g                  float64\n",
      "energy-from-fat_100g         float64\n",
      "fat_100g                     float64\n",
      "saturated-fat_100g           float64\n",
      "trans-fat_100g               float64\n",
      "cholesterol_100g             float64\n",
      "carbohydrates_100g           float64\n",
      "sugars_100g                  float64\n",
      "fiber_100g                   float64\n",
      "proteins_100g                float64\n",
      "salt_100g                    float64\n",
      "sodium_100g                  float64\n",
      "alcohol_100g                 float64\n",
      "calcium_100g                 float64\n",
      "iron_100g                    float64\n",
      "carbon-footprint_100g        float64\n",
      "nutrition-score-fr_100g      float64\n",
      "nutrition-score-uk_100g      float64\n",
      "glycemic-index_100g          float64\n",
      "dtype: object\n",
      "The total size of the data set is: (693984, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>manufacturing_places</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vit√≥ria crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130 g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendiants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salade de carottes r√¢p√©es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_name generic_name quantity brands brands_tags  \\\n",
       "0           Vit√≥ria crackers          NaN      NaN    NaN         NaN   \n",
       "1                      Cacao          NaN    130 g    NaN         NaN   \n",
       "2      Sauce Sweety chili 0%          NaN      NaN    NaN         NaN   \n",
       "3                  Mendiants          NaN      NaN    NaN         NaN   \n",
       "4  Salade de carottes r√¢p√©es          NaN      NaN    NaN         NaN   \n",
       "\n",
       "  categories categories_tags categories_en manufacturing_places  \\\n",
       "0        NaN             NaN           NaN                  NaN   \n",
       "1        NaN             NaN           NaN                  NaN   \n",
       "2        NaN             NaN           NaN                  NaN   \n",
       "3        NaN             NaN           NaN                  NaN   \n",
       "4        NaN             NaN           NaN                  NaN   \n",
       "\n",
       "  manufacturing_places_tags         ...         proteins_100g salt_100g  \\\n",
       "0                       NaN         ...                   7.8      1.40   \n",
       "1                       NaN         ...                   NaN       NaN   \n",
       "2                       NaN         ...                   0.2      2.04   \n",
       "3                       NaN         ...                   NaN       NaN   \n",
       "4                       NaN         ...                   0.9      0.42   \n",
       "\n",
       "  sodium_100g alcohol_100g calcium_100g iron_100g carbon-footprint_100g  \\\n",
       "0    0.551181          NaN          NaN       NaN                   NaN   \n",
       "1         NaN          NaN          NaN       NaN                   NaN   \n",
       "2    0.803150          NaN          NaN       NaN                   NaN   \n",
       "3         NaN          NaN          NaN       NaN                   NaN   \n",
       "4    0.165354          NaN          NaN       NaN                   NaN   \n",
       "\n",
       "  nutrition-score-fr_100g nutrition-score-uk_100g glycemic-index_100g  \n",
       "0                     NaN                     NaN                 NaN  \n",
       "1                     NaN                     NaN                 NaN  \n",
       "2                     NaN                     NaN                 NaN  \n",
       "3                     NaN                     NaN                 NaN  \n",
       "4                     NaN                     NaN                 NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The types of the data set are: \\n\", format(food_df.dtypes))\n",
    "print (\"The total size of the data set is:\", format(food_df.shape) )\n",
    "food_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name: 25881\n"
     ]
    }
   ],
   "source": [
    "# remove rows where the columns we are interested in are all null\n",
    "food_df = food_df.dropna(subset=using_col, how='all')\n",
    "print(\"Number of rows w/missing product_name: {}\".format(len(food_df) - food_df['product_name'].count()))\n",
    "saveFoodDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValueWithPriorityColumns(input_row, merging_columns):\n",
    "    for column in merging_columns:\n",
    "        if pd.notnull(input_row[column]):\n",
    "            return input_row[column]\n",
    "    return input_row[merging_columns[0]]\n",
    "\n",
    "def mergeColumnsFromDF(input_df, desired_columns, result_column):\n",
    "    if result_column in input_df.columns:\n",
    "        return input_df\n",
    "\n",
    "    input_df[result_column] = input_df.apply(\n",
    "        lambda x: getValueWithPriorityColumns(x,desired_columns),\n",
    "        axis = 1\n",
    "    )\n",
    "    for column in desired_columns:\n",
    "        if column in input_df.columns:\n",
    "            input_df = input_df.drop(column, axis=1)\n",
    "\n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateWithCache(value):\n",
    "    global translations\n",
    "    # search translated word in translations map\n",
    "    if value in translations:\n",
    "        # print(\"Cached  {} -> {}\".format(value,translations[value]))\n",
    "        return translations[value]\n",
    "    else:\n",
    "        try:\n",
    "            time.sleep(TRANSLATION_DELAY) \n",
    "            trns_value = translator.translate(text=value, dest='en')\n",
    "            if not trns_value is None:\n",
    "                new_translation=trns_value.text.lower()\n",
    "                # print(\"Translating {} -> {}\".format(value,new_translation))\n",
    "                translations[value]=new_translation\n",
    "                return new_translation\n",
    "            else:\n",
    "                print(\"None {} / {} / {}\".format(value,type(value), e))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Exception {} / {} / {}\".format(value,type(value), e))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and translate columns that are in the format \"language:value\"\n",
    "def parseTranslate(x, target_columns):\n",
    "    for column in target_columns:    \n",
    "        if (':') in x[column]:\n",
    "            info_ = x[column].split(':')\n",
    "            if len(info_) == 2:\n",
    "                value = info_[1]\n",
    "                return translateWithCache(value)\n",
    "        return x[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showProgress(size):\n",
    "    global PROGRESS \n",
    "    PROGRESS += 1\n",
    "    progress_value = int(100*PROGRESS/size)/100 \n",
    "    if (progress_value*100)%1==0:\n",
    "        sys.stdout.write('\\r'+'Progress {}%'.format(100*progress_value))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTranslations():\n",
    "    pd.DataFrame.from_dict(translations,orient=\"index\").T.to_csv(data_folder + translationsfile,sep='\\t')\n",
    "    \n",
    "def saveFoodDF():\n",
    "    food_df.to_csv(data_folder + foodfile,sep='\\t')\n",
    "\n",
    "def normalizeString(string):\n",
    "    return unidecode.unidecode(string.lower().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showNanPercentage(df,desired_columns):\n",
    "    for column in desired_columns:\n",
    "        print(\"Percentage of nan in {} is {}%\".format(column,100*len(df[df[column].isna()])/len(df) ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatAndTranslateRow(row, translateNoFormat):\n",
    "    showProgress(allergen_notna_df.shape[0])\n",
    "\n",
    "    if type(row) is not list and pd.notnull(row) :\n",
    "        raw_data = row.lower().split(',')\n",
    "        data = []\n",
    "        for value in raw_data:\n",
    "            value_ = normalizeString(value)\n",
    "            # format <langage_code:info>\n",
    "            if (':') in value_:\n",
    "                info_ = value_.split(':')\n",
    "                if len(info_) == 2:\n",
    "                    # already in english\n",
    "                    if info_[0] == 'en':\n",
    "                        data.append(info_[1])\n",
    "                    # translate to english\n",
    "                    else:\n",
    "                        data.append(translateWithCache(info_[1]))\n",
    "                else:\n",
    "                    data.append(info_)\n",
    "                #print(\"Appending {}\".format(info_))\n",
    "                \n",
    "            # no format, let's translate it\n",
    "            else:\n",
    "                if translateNoFormat:\n",
    "                    data.append(translateWithCache(value_))\n",
    "                else:\n",
    "                    data.append(value_)\n",
    "        #print(data)\n",
    "        return data                       \n",
    "    else:\n",
    "        return row\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing product_name\n",
    "This section deals with NaN values for `product_name`. If it does not have a `product_name`, the `generic_name` was used. If neither field was filled, then a combination of `brands` and `categories_en`/`main_category` was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    if pd.isnull(row['product_name']):\n",
    "        if pd.isnull(row['generic_name']):\n",
    "            if pd.isnull(row['main_category_en']) & pd.isnull(row['categories_en']) & pd.isnull(row['brands']):\n",
    "                return\n",
    "            else:\n",
    "                category_name = row['main_category_en']\n",
    "                if pd.isnull(category_name):\n",
    "                    category_name = row['categories_en']\n",
    "                return \"{} {}\".format(row['brands'], category_name)\n",
    "        else:\n",
    "            return row['generic_name']\n",
    "    else:\n",
    "        return row['product_name']\n",
    "    \n",
    "df = food_df.copy()\n",
    "\n",
    "df['product_name'] = df.apply(\n",
    "    lambda x: get_name(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows w/missing product_name after modifications: {}\".format(len(df) - df['product_name'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the columns that we no longer need\n",
    "used_col = [\n",
    "    'generic_name',\n",
    "    'main_category',\n",
    "    'main_category_en',\n",
    "    'brands',\n",
    "    'brands_tags',\n",
    "    'categories',\n",
    "    'categories_tags',\n",
    "    'categories_en',\n",
    "]\n",
    "\n",
    "df = df.drop(used_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the results, 22 458 rows still do not have names after our modifications. Our team decided that names were not of particular importance for our analysis, so we decided to leave these no-named items in the dataframe. The name is not important because we mostly want to analyze the ingredients of the items for each country. Thus the `labels`, `allergens`, and the numbers for sugar/sodium/calcium/etc and `countries` are the important columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Missing Values for Country\n",
    "This section deals with the missing values for `countries_en`. The `countries_en` column represents the countries where the product is sold. This column is important for our analysis because we want to analyze how viable it is to live in each country based off one's dietary restrictions.\n",
    "\n",
    "In order to fix these missing values, we decided to first fill the column with values from `purchase_places`, then `manufacturing_places`. We decided to use `purchase_places` because if it was purchased in a certain country, obviously it means the product is sold there as well. As for `manufacturing_places`, we assumed that it is most likely that a product manufactured in a country would be sold there as well.\n",
    "\n",
    "Furthermore, we looked at the column `origins`, however this column is actually describing where each ingredient came from. This would not be helpful for us because the origin would not tell us about which countries actually sell/consume this specific item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df) - df['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['countries_en'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_country(row):\n",
    "    if pd.isnull(row['countries_en']):\n",
    "        alt_country = None\n",
    "        if pd.notna(row['purchase_places']):\n",
    "            alt_country = row['purchase_places']\n",
    "        elif pd.notna(row['manufacturing_places']):\n",
    "            alt_country = row['manufacturing_places']\n",
    "            \n",
    "        # got value from purchase_places or manufacturing_places\n",
    "        if (not alt_country is None) and pd.notna(alt_country):\n",
    "            try:\n",
    "                en_alt_country = translator.translate(text=alt_country, dest='en')\n",
    "                if not en_alt_country is None:\n",
    "                    return en_alt_country.text\n",
    "            except Exception as e:\n",
    "                return alt_country\n",
    "            \n",
    "        return alt_country\n",
    "    else:\n",
    "        return row['countries_en']\n",
    "    \n",
    "df_1 = df.copy()\n",
    "\n",
    "df_1['countries_en'] = df_1.apply(\n",
    "    lambda x: translate_country(x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df_1) - df_1['countries_en'].count()))\n",
    "print(\"Percentage of rows w/missing countries_en: {0:.3f}%\".format(100*(len(df_1)-df_1['countries_en'].count())/len(df_1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows without country\n",
    "df_1 = df_1.dropna(subset=['countries_en'])\n",
    "\n",
    "\n",
    "print(\"Number of rows w/multiple countries: {}\".format(\n",
    "    len(df_1[df_1['countries_en'].str.contains(',')])))\n",
    "\n",
    "print(\"Number of total rows: {}\".format(len(df_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns that are no longer needed\n",
    "used_col = [\n",
    "    'purchase_places',\n",
    "    'manufacturing_places',\n",
    "    'manufacturing_places_tags',\n",
    "    'countries_tags',\n",
    "    'countries',\n",
    "]\n",
    "\n",
    "df_1 = df_1.drop(used_col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows that some countries_en are lists\n",
    "df_1[df_1['countries_en'].notnull() & df_1['countries_en'].str.contains(',')][['countries_en', 'product_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts the list substring into an array\n",
    "df_2 = df_1.copy()\n",
    "\n",
    "df_2['countries_en'] = df_2.apply(\n",
    "    lambda x: [x.strip() for x in x['countries_en'].split(',')],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "# [x.strip() for x in my_string.split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shows that the countries has been properly split\n",
    "df_2[df_2.index == 173][['product_name', 'countries_en']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this subsection deals with standardizing the countries for each product. First, we notice that some products have more than one country in their `countries_en` field. In this case, we seperate/explode each country in the `countries_en` field so that each country has its own row for that item. Next, we join the countries with their respective country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the countries_en to country codes\n",
    "country_df = pd.read_csv(data_folder + countryfile, \n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         usecols=['English short name lower case', 'Alpha-2 code'],\n",
    "                         quotechar='\"')\n",
    "# rename columns\n",
    "country_df.rename(columns={\n",
    "    'Alpha-2 code':'country_code',\n",
    "    'English short name lower case': 'country_name'\n",
    "    }, inplace=True)\n",
    "\n",
    "country_df['country_name'] = country_df.apply(\n",
    "    lambda x: x['country_name'].lower(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]\n",
    "\n",
    "df_3 = df_2.copy()\n",
    "df_3 = explode(df_3,'countries_en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how the explode function created another row because there were two countries for Lion Peanut x2\n",
    "df_3[df_3['product_name'].notna() & df_3['product_name'].str.contains('Lion Peanut x2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "# rename countries_en to country_name\n",
    "df_4.rename(columns={'countries_en':'country_name'}, inplace=True)\n",
    "\n",
    "df_4['country_name'] = df_4.apply(\n",
    "    lambda x: x['country_name'].lower(),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to check the stats of the rows with a country_name but still without a country_code\n",
    "def notAssigned(df_sample):\n",
    "    not_assigned = df_sample[df_sample['country_name'].notna() & df_sample['country_code'].isna()]\n",
    "\n",
    "    print(\"Number of unassigned items is: {}\".format(len(not_assigned)))\n",
    "    print(\"The important values are: \")\n",
    "    print(not_assigned['country_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_4.copy()\n",
    "\n",
    "df_5 = df_5.merge(country_df, how='left')\n",
    "    \n",
    "notAssigned(df_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to fix the country codes with the highest frequency, since the importance/effect of fixing the lower values will decrease as we descend through the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Russian Federation to russia\n",
    "country_df['country_name'][country_df['country_code'] == 'RU'] = 'russia'\n",
    "\n",
    "# changing Korea, Republic of to south korea\n",
    "country_df['country_name'][country_df['country_code'] == 'KR'] = 'south korea'\n",
    "\n",
    "# changing Macedonia, the former Yugoslav Republic of to republic of macedonia\n",
    "country_df['country_name'][country_df['country_code'] == 'MK'] = 'republic of macedonia'\n",
    "\n",
    "# changing Taiwan, Province of China to taiwan\n",
    "country_df['country_name'][country_df['country_code'] == 'TW'] = 'taiwan'\n",
    "\n",
    "# changing Viet Nam to vietnam\n",
    "country_df['country_name'][country_df['country_code'] == 'VN'] = 'vietnam'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis of the unpaired countries, we see that a few countries are still in another language. Specifically, they are in the format \"language:country\". The method `parseTranslate` tries to deal with this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6 = df_4.copy()\n",
    "\n",
    "df_6['country_name'] = df_6.apply(\n",
    "    lambda x: parseTranslate(x,['country_name']),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our description of the countries still missing country codes, it is found that most of these countries do not have the full name as the one in the CSV file `country_df`. Thus, we try to find the `best_match` and change the `country_name` in the food dataframe to match the one in the `country_df`. We consider something a `best_match` if the `country_name` from the food dataframe is a substring of the `country_name` in the country dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_6 = df_6.merge(country_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display result\n",
    "df_6[['product_name','country_name','country_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match(country_df, row):\n",
    "    if pd.isnull(row['country_code']):\n",
    "        countries = list(country_df['country_name'])\n",
    "        for country in countries:\n",
    "            if row['country_name'] in country:\n",
    "                return country\n",
    "\n",
    "    return row['country_name']\n",
    "\n",
    "df_6['country_name'] = df_6.apply(\n",
    "    lambda x: best_match(country_df, x),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = df_6.drop(['country_code'], axis=1)\n",
    "\n",
    "df_7 = df_7.merge(country_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notAssigned(df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = df_7[df_7['country_code'].notna()]\n",
    "print(\"Number of rows with a country code: {}\".format(len(df_8)))\n",
    "print(\"Number of total rows: {}\".format(len(food_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows we can use (meaning the rows with a `country_code`) is higher than what we original started with because we made duplicates of some rows so that each country has its own instance of the item. An issue we ran into is that with the high number of translations we need to do, Google's API will eventually block our requests,thus some more rows might have actually been able to be paired up with a `country_code`. To try a walka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing nutrition scores\n",
    "\n",
    "This section deals with NaN values for `nutrition score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns=[\n",
    "    'nutrition_grade_uk',\n",
    "    'nutrition_grade_fr',\n",
    "    'nutrition-score-fr_100g',\n",
    "    'nutrition-score-uk_100g'\n",
    "]\n",
    "result_column='nutrition_score'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in desired_columns:\n",
    "    print(\"Percentage of nan in {} is {}%\".format(column,100*len(food_df[food_df[column].isna()])/len(food_df) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that `nutrition_grade_uk` is always nan and that `nutrition_grade_fr`, `nutrition-score-fr_100g` and `nutrition-score-uk_100g` have exactly the same value. For this reason, the column used is `nutrition_grade_fr`. Nan values are not filled since for now, the nutrition score is going to be an additional indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_df = food_df.copy()\n",
    "nutrition_df[result_column]=nutrition_df[desired_columns[1]] #.fillna(UNKNOWN_STR)\n",
    "nutrition_df = nutrition_df.drop(desired_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in missing allergens\n",
    "\n",
    "This section deals with NaN values for `allergens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns=[\n",
    "    'allergens_en',\n",
    "    'allergens'\n",
    "]\n",
    "result_column='allergen_values'\n",
    "allergen_df=food_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showNanPercentage(food_df,desired_columns)\n",
    "allergen_df[allergen_df[desired_columns[0]].notna()][desired_columns].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result, both columns have different percentages, for some reason, values in `allergens_en` are urls so for further analysis only the `allergen` column is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergen_df[result_column]=allergen_df[desired_columns[1]]\n",
    "allergen_df1 = allergen_df.drop(desired_columns, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the allergens format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergen_notna_df=allergen_df1[allergen_df1[result_column].notna()].copy()\n",
    "allergen_notna_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of the `result column` by assuring values are strings lowercase before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allergen_notna_df[result_column].apply(str)\n",
    "allergen_notna_df[result_column] = allergen_notna_df[result_column].apply(\n",
    "    lambda x: x.lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the helper function `formatAndTranslateRow`, allergen rows are going to be formated to an array and translated to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100.0%"
     ]
    }
   ],
   "source": [
    "PROGRESS=0\n",
    "allergen_notna_df[result_column] = allergen_notna_df[result_column].apply(\n",
    "    lambda x: formatAndTranslateRow(x,True)\n",
    ")\n",
    "saveTranslations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10                                       [eggs, mustard]\n",
       "22     [corn, gluten, became, cheese, milk, milk, mil...\n",
       "31                [corn, rye, corn, rye, salmon, cheese]\n",
       "39                                              [cheese]\n",
       "44     [corn, gluten, became, became, barley, corn, s...\n",
       "46                                        [eggs, gluten]\n",
       "282                                                [soy]\n",
       "293                       [corn, butter, eggs, hazelnut]\n",
       "315                                   [almonds, almonds]\n",
       "342                                     [milk, hazelnut]\n",
       "Name: allergen_values, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(allergen_notna_df.shape[0])\n",
    "allergen_notna_df[allergen_notna_df[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "allergen_df1_=allergen_df1.rename(columns = {result_column:'old_values'})['old_values']\n",
    "allergen_df1[result_column]=pd.concat([allergen_df1_, allergen_notna_df], axis=1, join_axes=[allergen_df1.index])[result_column]           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693846, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10                                       [eggs, mustard]\n",
       "22     [corn, gluten, became, cheese, milk, milk, mil...\n",
       "31                [corn, rye, corn, rye, salmon, cheese]\n",
       "39                                              [cheese]\n",
       "44     [corn, gluten, became, became, barley, corn, s...\n",
       "46                                        [eggs, gluten]\n",
       "282                                                [soy]\n",
       "293                       [corn, butter, eggs, hazelnut]\n",
       "315                                   [almonds, almonds]\n",
       "342                                     [milk, hazelnut]\n",
       "Name: allergen_values, dtype: object"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(allergen_df1.shape)\n",
    "allergen_df1[allergen_df1[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of nan in allergen_values is 90.07445456196332%\n"
     ]
    }
   ],
   "source": [
    "showNanPercentage(allergen_df1,[result_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in traces\n",
    "\n",
    "This section deals with NaN values for `traces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns=[\n",
    "    'traces_en',\n",
    "    'traces'\n",
    "]\n",
    "result_column='traces_values'\n",
    "traces_df=food_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces_df_=mergeColumnsFromDF(traces_df, desired_columns, result_column)\n",
    "traces_notna_df=traces_df_[traces_df_[result_column].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of nan in traces_values is 91.46035287369243%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111                                            Eggs,Milk\n",
       "129                                         Sesame seeds\n",
       "220    Eggs,Gluten,Milk,Nuts,Soybeans,Oatmeal,Wheatflour\n",
       "255    fr:contient-oeuf-lait-anchois-soya-ble-seigle-...\n",
       "275    Soybeans,Sulphur dioxide and sulphites,fr:cont...\n",
       "Name: traces_values, dtype: object"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showNanPercentage(traces_df_,[result_column])\n",
    "traces_notna_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 4.0%Exception arete / <class 'str'> / ('Connection aborted.', OSError(\"(60, 'ETIMEDOUT')\",))\n",
      "Progress 4.0%Exception du-celeri-et-du-sesame / <class 'str'> / Expecting value: line 1 column 1 (char 0)\n",
      "Exception fabrique-dans-un-atelier-qui-utilise-des-fruits-a-coques / <class 'str'> / Expecting value: line 1 column 1 (char 0)\n",
      "Progress 4.0%Exception de-lupin-et-de-graines-de-sesames / <class 'str'> / Expecting value: line 1 column 1 (char 0)\n",
      "Progress 4.0%Exception huile-de-palme / <class 'str'> / Expecting value: line 1 column 1 (char 0)\n",
      "Progress 4.0%Exception noix-de-coco / <class 'str'> / ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response',))\n",
      "Progress 23.0%Exception sesae / <class 'str'> / ('Connection aborted.', OSError(\"(65, 'EHOSTUNREACH')\",))\n",
      "Progress 86.0%"
     ]
    }
   ],
   "source": [
    "PROGRESS=0\n",
    "traces_notna_df[result_column] = traces_notna_df[result_column].apply(\n",
    "    lambda x: formatAndTranslateRow(x,False)\n",
    ")\n",
    "saveTranslations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111                                         [eggs, milk]\n",
       "129                                       [sesame seeds]\n",
       "220    [eggs, gluten, milk, nuts, soybeans, oatmeal, ...\n",
       "255    [contains egg-milk-anchovy-soy-wheat-rye-barle...\n",
       "275    [soybeans, sulphur dioxide and sulphites, cont...\n",
       "286    [gluten, may contain nuts, soy-varied-milk-egg...\n",
       "293                       [nuts, sesame seeds, soybeans]\n",
       "299    [celery, crustaceans, eggs, fish, gluten, milk...\n",
       "300                                               [eggs]\n",
       "306    [eggs, gluten, milk, mustard, nuts, sesame see...\n",
       "Name: traces_values, dtype: object"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(traces_notna_df.shape[0])\n",
    "traces_notna_df[traces_notna_df[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling in Ingredients\n",
    "This section deals with NaN values for `ingredients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_columns=[\n",
    "    'ingredients_text'\n",
    "]\n",
    "result_column='ingredients_text'\n",
    "ingredients_df=food_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of nan in ingredients_text is 43.29880117490048%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>antioxydant : √©rythorbate de sodium, colorant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lait entier, sucre, amidon de ma√Øs, cacao, Aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>baguette Poite vin Pain baguette 50,6%: fqrine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Paln su√©dois 42,6%: farine de BL√â, eau, farine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Taboul√© 76,2%, l√©gumes 12%, huile de colza, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ingredients_text\n",
       "10  antioxydant : √©rythorbate de sodium, colorant ...\n",
       "15  Lait entier, sucre, amidon de ma√Øs, cacao, Aga...\n",
       "22  baguette Poite vin Pain baguette 50,6%: fqrine...\n",
       "31  Paln su√©dois 42,6%: farine de BL√â, eau, farine...\n",
       "33  Taboul√© 76,2%, l√©gumes 12%, huile de colza, se..."
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showNanPercentage(food_df,desired_columns)\n",
    "ingredients_df[ingredients_df[desired_columns[0]].notna()][desired_columns].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"antioxydant : √©rythorbate de sodium, colorant : caramel - origine UE), tomate 33,3%, MAYONNAISE 11,1% (huile de colza 78,9%, eau, jaunes d'OEUF 6%, vinaigre, MOUTARDE [eau, graines de MOUTARDE, sel, vinaigre, curcuma], sel, dextrose, stabilisateur : gomme de cellulose, conservateur : sorbate de potassium, colorant : ?-carot√®ne, ar√¥me)\""
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_notna_df=ingredients_df[ingredients_df[result_column].notna()].copy()\n",
    "ingredients_notna_df[result_column].loc[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['antioxydant ',\n",
       " ' √©rythorbate de sodium, colorant ',\n",
       " \" caramel - origine UE), tomate 33,3%, MAYONNAISE 11,1% (huile de colza 78,9%, eau, jaunes d'OEUF 6%, vinaigre, MOUTARDE [eau, graines de MOUTARDE, sel, vinaigre, curcuma], sel, dextrose, stabilisateur \",\n",
       " ' gomme de cellulose, conservateur ',\n",
       " ' sorbate de potassium, colorant ',\n",
       " ' ?-carot√®ne, ar√¥me)']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_notna_df[result_column].loc[10].split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROGRESS=0\n",
    "ingredients_notna_df[result_column] = ingredients_notna_df[result_column].apply(\n",
    "    lambda x: formatAndTranslateRow(x,True)\n",
    ")\n",
    "saveTranslations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ingredients_notna_df.shape[0])\n",
    "traces_notna_df[ingredients_notna_df[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization & Analysis\n",
    "TO BE COMPLETED FOR MILESTONE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5805"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTranslations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
