{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Food Facts Notebook\n",
    "## Table of Contents\n",
    "1. [Helper Functions](#Helper-Functions) \n",
    "2. [Cleaning Data](#Cleaning-Data)  \n",
    "    2.1 [Fill in missing Product Name](#product_name)  \n",
    "    2.2 [Fill in Missing Values for Country](#country)  \n",
    "    2.3 [Fill in Missing Nutrion Scores](#nutrition-scores)  \n",
    "    2.4 [Fill in Missing Allergens](#allergens)  \n",
    "    2.5 [Fill in Missing Traces](#traces)  \n",
    "    2.6 [Fill/Clean Ingredients](#ingredients)  \n",
    "    2.7 [Fill/Clean Labels](#labels_column)  \n",
    "    2.8 [Clean float64 Columns](#float64_col)  \n",
    "3. [Data Visualization & Analysis](#data_analysis)  \n",
    "    3.1 [Maps](#Maps)  \n",
    "    3.2 [Correlations Between Neighbouring Countries](#correlation_neighbours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "#import folium\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#from google.cloud import translate\n",
    "#import pycountry\n",
    "#import emoji\n",
    "\n",
    "#translate_client = translate.Client()\n",
    "\n",
    "import sys # for printing process\n",
    "import unidecode # for normalizing text\n",
    "from pathlib import Path # check files\n",
    "\n",
    "\n",
    "from py_translator import Translator\n",
    "translator = Translator()\n",
    "\n",
    "# from googletrans import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WE HAD DIFFICULTIES MERGING, FATS CLEANING IS IN `project_fats` FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a data folder where the .csv file will be stored and also a maps folder where .html maps will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'en.openfoodfacts.org.products.csv'\n",
    "countryfile = 'wikipedia-iso-country-codes.csv'\n",
    "translationsfile = 'translations.csv'\n",
    "foodfile = 'food.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_col = [\n",
    "    \"product_name\",\n",
    "    \"generic_name\",\n",
    "    \"quantity\",\n",
    "    \"brands\",\n",
    "    \"brands_tags\",\n",
    "    \"categories\",\n",
    "    \"categories_tags\",\n",
    "    \"categories_en\",\n",
    "    \"manufacturing_places\",\n",
    "    \"manufacturing_places_tags\",\n",
    "    \"labels\",\n",
    "    \"labels_tags\",\n",
    "    \"labels_en\",\n",
    "    \"purchase_places\",\n",
    "    \"countries\",\n",
    "    \"countries_tags\",\n",
    "    \"countries_en\",\n",
    "    \"ingredients_text\",\n",
    "    \"allergens\",\n",
    "    \"allergens_en\",\n",
    "    \"traces\",\n",
    "    \"traces_tags\",\n",
    "    \"traces_en\",\n",
    "    \"nutrition_grade_uk\",\n",
    "    \"nutrition_grade_fr\",\n",
    "    \"main_category\",\n",
    "    \"main_category_en\",\n",
    "    \"energy_100g\",\n",
    "    \"energy-from-fat_100g\",\n",
    "    \"fat_100g\",\n",
    "    \"saturated-fat_100g\",\n",
    "    \"trans-fat_100g\",\n",
    "    \"cholesterol_100g\",\n",
    "    \"carbohydrates_100g\",\n",
    "    \"sugars_100g\",\n",
    "    \"fiber_100g\",\n",
    "    \"proteins_100g\",\n",
    "    \"salt_100g\",\n",
    "    \"sodium_100g\",\n",
    "    \"alcohol_100g\",\n",
    "    \"calcium_100g\",\n",
    "    \"iron_100g\",\n",
    "    \"carbon-footprint_100g\",\n",
    "    \"nutrition-score-fr_100g\",\n",
    "    \"nutrition-score-uk_100g\",\n",
    "    \"glycemic-index_100g\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './data/'\n",
    "maps_folder = './maps/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "# unknown values to use\n",
    "UNKNOWN_NR='-1'\n",
    "UNKNOWN_STR='unknown'\n",
    "# delay between translation requests\n",
    "TRANSLATION_DELAY=0.3\n",
    "# progress in function\n",
    "PROGRESS=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translations file found\n",
      "7435 translations found\n"
     ]
    }
   ],
   "source": [
    "# cache translations to save translation requests\n",
    "translations_file = Path(data_folder + translationsfile)\n",
    "translations = {}\n",
    "\n",
    "if not translations_file.is_file():\n",
    "    print('Translations file not found')\n",
    "else:\n",
    "    print('Translations file found')\n",
    "    translations = pd.read_csv(data_folder + translationsfile, \n",
    "                               sep='\\t',\n",
    "                               low_memory=False).to_dict(\"records\")[0]\n",
    "    print('{} translations found'.format(len(translations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food file found\n",
      "693846 Food entries found\n"
     ]
    }
   ],
   "source": [
    "food_file = Path(data_folder + foodfile)\n",
    "food_df = pd.DataFrame()\n",
    "\n",
    "if not food_file.is_file():\n",
    "    print('Food file not found')\n",
    "    food_df = pd.read_csv(data_folder + filename, \n",
    "                      sep='\\t',\n",
    "                      usecols = using_col,\n",
    "                      quotechar='\"', \n",
    "                      low_memory=False)\n",
    "else:\n",
    "    print('Food file found')\n",
    "    food_df = pd.read_csv(data_folder + foodfile, \n",
    "                      sep='\\t',\n",
    "                      low_memory=False)\n",
    "    print('{} Food entries found'.format(len(food_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The types of the data set are: \n",
      " product_name                  object\n",
      "generic_name                  object\n",
      "quantity                      object\n",
      "brands                        object\n",
      "brands_tags                   object\n",
      "categories                    object\n",
      "categories_tags               object\n",
      "categories_en                 object\n",
      "manufacturing_places          object\n",
      "manufacturing_places_tags     object\n",
      "labels                        object\n",
      "labels_tags                   object\n",
      "labels_en                     object\n",
      "purchase_places               object\n",
      "countries                     object\n",
      "countries_tags                object\n",
      "countries_en                  object\n",
      "ingredients_text              object\n",
      "allergens                     object\n",
      "allergens_en                  object\n",
      "traces                        object\n",
      "traces_tags                   object\n",
      "traces_en                     object\n",
      "nutrition_grade_uk           float64\n",
      "nutrition_grade_fr            object\n",
      "main_category                 object\n",
      "main_category_en              object\n",
      "energy_100g                  float64\n",
      "energy-from-fat_100g         float64\n",
      "fat_100g                     float64\n",
      "saturated-fat_100g           float64\n",
      "trans-fat_100g               float64\n",
      "cholesterol_100g             float64\n",
      "carbohydrates_100g           float64\n",
      "sugars_100g                  float64\n",
      "fiber_100g                   float64\n",
      "proteins_100g                float64\n",
      "salt_100g                    float64\n",
      "sodium_100g                  float64\n",
      "alcohol_100g                 float64\n",
      "calcium_100g                 float64\n",
      "iron_100g                    float64\n",
      "carbon-footprint_100g        float64\n",
      "nutrition-score-fr_100g      float64\n",
      "nutrition-score-uk_100g      float64\n",
      "glycemic-index_100g          float64\n",
      "dtype: object\n",
      "The total size of the data set is: (693846, 46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>manufacturing_places</th>\n",
       "      <th>manufacturing_places_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>proteins_100g</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vitória crackers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.551181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cacao</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130 g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sauce Sweety chili 0%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mendiants</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salade de carottes râpées</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.165354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                product_name generic_name quantity brands brands_tags  \\\n",
       "0           Vitória crackers          NaN      NaN    NaN         NaN   \n",
       "1                      Cacao          NaN    130 g    NaN         NaN   \n",
       "2      Sauce Sweety chili 0%          NaN      NaN    NaN         NaN   \n",
       "3                  Mendiants          NaN      NaN    NaN         NaN   \n",
       "4  Salade de carottes râpées          NaN      NaN    NaN         NaN   \n",
       "\n",
       "  categories categories_tags categories_en manufacturing_places  \\\n",
       "0        NaN             NaN           NaN                  NaN   \n",
       "1        NaN             NaN           NaN                  NaN   \n",
       "2        NaN             NaN           NaN                  NaN   \n",
       "3        NaN             NaN           NaN                  NaN   \n",
       "4        NaN             NaN           NaN                  NaN   \n",
       "\n",
       "  manufacturing_places_tags         ...         proteins_100g salt_100g  \\\n",
       "0                       NaN         ...                   7.8      1.40   \n",
       "1                       NaN         ...                   NaN       NaN   \n",
       "2                       NaN         ...                   0.2      2.04   \n",
       "3                       NaN         ...                   NaN       NaN   \n",
       "4                       NaN         ...                   0.9      0.42   \n",
       "\n",
       "  sodium_100g alcohol_100g calcium_100g iron_100g carbon-footprint_100g  \\\n",
       "0    0.551181          NaN          NaN       NaN                   NaN   \n",
       "1         NaN          NaN          NaN       NaN                   NaN   \n",
       "2    0.803150          NaN          NaN       NaN                   NaN   \n",
       "3         NaN          NaN          NaN       NaN                   NaN   \n",
       "4    0.165354          NaN          NaN       NaN                   NaN   \n",
       "\n",
       "  nutrition-score-fr_100g nutrition-score-uk_100g glycemic-index_100g  \n",
       "0                     NaN                     NaN                 NaN  \n",
       "1                     NaN                     NaN                 NaN  \n",
       "2                     NaN                     NaN                 NaN  \n",
       "3                     NaN                     NaN                 NaN  \n",
       "4                     NaN                     NaN                 NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The types of the data set are: \\n\", format(food_df.dtypes))\n",
    "print (\"The total size of the data set is:\", format(food_df.shape) )\n",
    "food_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved module: food\n"
     ]
    }
   ],
   "source": [
    "# remove rows where the columns we are interested in are all null\n",
    "food_df = food_df.dropna(subset=using_col, how='all')\n",
    "saveFoodDF(food_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the first non null value from gibben collumns in priority order\n",
    "def getValueWithPriorityColumns(input_row, merging_columns):\n",
    "    for column in merging_columns:\n",
    "        if pd.notnull(input_row[column]):\n",
    "            return input_row[column]\n",
    "    return input_row[merging_columns[0]]\n",
    "\n",
    "# Merges from a input DF the desired columns into a result column\n",
    "def mergeColumnsFromDF(input_df, desired_columns, result_column):\n",
    "    if result_column in input_df.columns:\n",
    "        return input_df\n",
    "\n",
    "    input_df[result_column] = input_df.apply(\n",
    "        lambda x: getValueWithPriorityColumns(x,desired_columns),\n",
    "        axis = 1\n",
    "    )\n",
    "    for column in desired_columns:\n",
    "        if column in input_df.columns:\n",
    "            input_df = input_df.drop(column, axis=1)\n",
    "\n",
    "    return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translates a value and saves it to translations cache dict\n",
    "def translateWithCache(value):\n",
    "    global translations\n",
    "    # search translated word in translations map\n",
    "    if value in translations:\n",
    "        # print(\"Cached  {} -> {}\".format(value,translations[value]))\n",
    "        return translations[value]\n",
    "    else:\n",
    "        try:\n",
    "            print(1)\n",
    "            time.sleep(TRANSLATION_DELAY) \n",
    "            print(2)\n",
    "            trns_value = translator.translate(text=value, dest='en')\n",
    "            if not trns_value is None:\n",
    "                new_translation=trns_value.text.lower()\n",
    "                print(\"Translating {} -> {}\".format(value,new_translation))\n",
    "                translations[value]=new_translation\n",
    "                return new_translation\n",
    "            else:\n",
    "                print(\"None {} / {} / {}\".format(value,type(value), e))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(\"Exception {} / {} / {}\".format(value,type(value), e))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-9977efe62ecb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_acquirer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'èè'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pepe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#translator.translate(text='Hello my friend', dest='es').text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ada/lib/python3.6/site-packages/py_translator/client.py\u001b[0m in \u001b[0;36mdetect\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# actual source language that will be recognized by Google Translator when the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ada/lib/python3.6/site-packages/py_translator/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_acquirer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         params = utils.build_params(query=text, src=src, dest=dest,\n\u001b[1;32m     77\u001b[0m                                     token=token)\n",
      "\u001b[0;32m/anaconda3/envs/ada/lib/python3.6/site-packages/py_translator/gtoken.py\u001b[0m in \u001b[0;36mdo\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ada/lib/python3.6/site-packages/py_translator/gtoken.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# we don't need to update the base TKK value when it is still valid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtkk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRE_TKK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m3600000.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "translator.token_acquirer.acquire('èè')\n",
    "translator.detect('pepe')\n",
    "#translator.translate(text='Hello my friend', dest='es').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file translations dict\n",
    "def saveTranslations():\n",
    "    pd.DataFrame.from_dict(translations,orient=\"index\").T.to_csv(data_folder + translationsfile,sep='\\t',index=False)\n",
    "\n",
    "# Save to file a dataframe with gibben name\n",
    "def saveModuleDF(name,df):\n",
    "    df.to_csv(data_folder + name + '.csv', sep='\\t',index=False)\n",
    "    print('Saved module: {}'.format(name))\n",
    "\n",
    "# Save to file food dataframe \n",
    "def saveFoodDF(df):\n",
    "    saveModuleDF('food',df)\n",
    "\n",
    "# Looks for existing file saved and returns it if found or a food_df copy\n",
    "def getModuleDF(name):\n",
    "    file_name=data_folder + name + '.csv'\n",
    "    file = Path(file_name)\n",
    "\n",
    "    if not file.is_file():\n",
    "        print('{} file not found'.format(name))\n",
    "        return food_df.copy()\n",
    "    else:\n",
    "        print('{} file found'.format(name))\n",
    "        df = pd.read_csv(file_name, \n",
    "                          sep='\\t',\n",
    "                          low_memory=False)\n",
    "        print('{} {} entries found'.format(len(df),name))\n",
    "        return df\n",
    "\n",
    "    \n",
    "    \n",
    "# Removes special character, numbers, accents, sets to lower case and removes trailing spaces\n",
    "def normalizeString(string):\n",
    "    cleaned=''.join([i for i in string if (i.isalnum() & ~i.isdigit()) | i.isspace() ])\n",
    "    return unidecode.unidecode(cleaned.lower().strip())\n",
    "\n",
    "# Removes array without duplicate values\n",
    "def removeDuplcates(array):\n",
    "    newItems=[]\n",
    "    for item in array:\n",
    "        if item and item not in newItems:\n",
    "            newItems.append(item)\n",
    "    \n",
    "    return newItems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows progress during processing\n",
    "def showProgress(size):\n",
    "    global PROGRESS \n",
    "    PROGRESS += 1\n",
    "    progress_value = int(10000*PROGRESS/size)/100\n",
    "    if (progress_value*100)%1==0:\n",
    "        sys.stdout.write('\\r'+'Progress {}%'.format(progress_value))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "# Show NaN percentage of column values in input df    \n",
    "def showNanPercentage(df,desired_columns):\n",
    "    for column in desired_columns:\n",
    "        print(\"Percentage of NaN in {} is {:.2f}%\".format(column,100*len(df[df[column].isna()])/len(df) ))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formats and translate rows formated as a list of values\n",
    "def formatAndTranslateRow(row, translateNoFormat):\n",
    "    showProgress(allergen_notna_df.shape[0])\n",
    "\n",
    "    if type(row) is not list and pd.notnull(row) :\n",
    "        raw_data = row.lower().split(',')\n",
    "        data = []\n",
    "        for value in raw_data:\n",
    "            value_ = normalizeString(value)\n",
    "            # format <langage_code:info>\n",
    "            if (':') in value_:\n",
    "                info_ = value_.split(':')\n",
    "                if len(info_) == 2:\n",
    "                    # already in english\n",
    "                    if info_[0] == 'en':\n",
    "                        data.append(info_[1])\n",
    "                    # translate to english\n",
    "                    else:\n",
    "                        data.append(translateWithCache(info_[1]))\n",
    "                else:\n",
    "                    data.append(info_)\n",
    "                #print(\"Appending {}\".format(info_))\n",
    "                \n",
    "            # no format, let's translate it\n",
    "            else:\n",
    "                if translateNoFormat:\n",
    "                    data.append(translateWithCache(value_))\n",
    "                else:\n",
    "                    data.append(value_)\n",
    "        #print(data)\n",
    "        return data                       \n",
    "    else:\n",
    "        return row\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Product Name <a id=\"product_name\"></a>\n",
    "\n",
    "This section deals with NaN values for `product_name`. If it does not have a `product_name`, the `generic_name` was used. If neither field was filled, then a combination of `brands` and `categories_en`/`main_category` was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in product_name is 3.73%\n",
      "Percentage of NaN in generic_name is 88.88%\n",
      "Percentage of NaN in main_category is 74.23%\n",
      "Percentage of NaN in main_category_en is 74.23%\n",
      "Percentage of NaN in brands is 33.17%\n",
      "Percentage of NaN in brands_tags is 33.18%\n",
      "Percentage of NaN in categories is 74.21%\n",
      "Percentage of NaN in categories_tags is 74.21%\n",
      "Percentage of NaN in categories_en is 74.22%\n"
     ]
    }
   ],
   "source": [
    "desired_columns = [\n",
    "    'product_name',\n",
    "    'generic_name',\n",
    "    'main_category',\n",
    "    'main_category_en',\n",
    "    'brands',\n",
    "    'brands_tags',\n",
    "    'categories',\n",
    "    'categories_tags',\n",
    "    'categories_en',\n",
    "]\n",
    "\n",
    "result_column='product_name_value'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_name_value file found\n",
      "693846 product_name_value entries found\n",
      "Found module: True\n"
     ]
    }
   ],
   "source": [
    "df = getModuleDF(result_column)\n",
    "FOUND_MODULE = result_column in df.columns\n",
    "print(\"Found module: {}\".format(FOUND_MODULE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(row):\n",
    "    showProgress(df.shape[0])\n",
    "    if pd.isnull(row['product_name']):\n",
    "        if pd.isnull(row['generic_name']):\n",
    "            if pd.isnull(row['main_category_en']) & pd.isnull(row['categories_en']) & pd.isnull(row['brands']):\n",
    "                return\n",
    "            else:\n",
    "                category_name = row['main_category_en']\n",
    "                if pd.isnull(category_name):\n",
    "                    category_name = row['categories_en']\n",
    "                return \"{} {}\".format(row['brands'], category_name)\n",
    "        else:\n",
    "            return row['generic_name']\n",
    "    else:\n",
    "        return row['product_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FOUND_MODULE:\n",
    "    PROGRESS=0\n",
    "    \n",
    "    df[result_column] = df.apply(\n",
    "        lambda x: get_name(x),\n",
    "        axis = 1\n",
    "    )\n",
    "    \n",
    "    # removing the columns that we no longer need\n",
    "    df = df.drop(desired_columns, axis=1)\n",
    "    saveModuleDF(result_column,df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing product_name after modifications: 22458\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing product_name after modifications: {}\".format(len(df) - df[result_column].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the results, 22 458 rows still do not have names after our modifications. Our team decided that names were not of particular importance for our analysis, so we decided to leave these no-named items in the dataframe. The name is not important because we mostly want to analyze the ingredients of the items for each country. Thus the `labels`, `allergens`, and the numbers for sugar/sodium/calcium/etc and `countries` are the important columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Values for Country <a id=\"country\"></a>\n",
    "This section deals with the missing values for `countries_en`. The `countries_en` column represents the countries where the product is sold. This column is important for our analysis because we want to analyze how viable it is to live in each country based off one's dietary restrictions.\n",
    "\n",
    "In order to fix these missing values, we decided to first fill the column with values from `purchase_places`, then `manufacturing_places`. We decided to use `purchase_places` because if it was purchased in a certain country, obviously it means the product is sold there as well. As for `manufacturing_places`, we assumed that it is most likely that a product manufactured in a country would be sold there as well.\n",
    "\n",
    "Furthermore, we looked at the column `origins`, however this column is actually describing where each ingredient came from. This would not be helpful for us because the origin would not tell us about which countries actually sell/consume this specific item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in countries_en is 0.07%\n",
      "Percentage of NaN in purchase_places is 85.51%\n",
      "Percentage of NaN in manufacturing_places is 90.35%\n",
      "Percentage of NaN in manufacturing_places_tags is 90.35%\n",
      "Percentage of NaN in countries_tags is 0.07%\n",
      "Percentage of NaN in countries is 0.07%\n"
     ]
    }
   ],
   "source": [
    "desired_columns = [\n",
    "    'countries_en',\n",
    "    'purchase_places',\n",
    "    'manufacturing_places',\n",
    "    'manufacturing_places_tags',\n",
    "    'countries_tags',\n",
    "    'countries'\n",
    "]\n",
    "\n",
    "result_column='country_name'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "countries_values file not found\n",
      "Found module: False\n"
     ]
    }
   ],
   "source": [
    "df_1 = getModuleDF(result_column)\n",
    "FOUND_MODULE = result_column in df.columns\n",
    "print(\"Found module: {}\".format(FOUND_MODULE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 459\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df) - df['countries_en'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693387"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['countries_en'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_country(row,size):\n",
    "    showProgress(size)\n",
    "    if pd.isnull(row['countries_en']):\n",
    "        alt_country = None\n",
    "        if pd.notna(row['purchase_places']):\n",
    "            alt_country = row['purchase_places']\n",
    "        elif pd.notna(row['manufacturing_places']):\n",
    "            alt_country = row['manufacturing_places']\n",
    "            \n",
    "        # got value from purchase_places or manufacturing_places\n",
    "        if (not alt_country is None) and pd.notna(alt_country):\n",
    "            try:\n",
    "                en_alt_country = translateWithCache(alt_country)\n",
    "                if not en_alt_country is None:\n",
    "                    return en_alt_country.text\n",
    "            except Exception as e:\n",
    "                return alt_country\n",
    "            \n",
    "        return alt_country\n",
    "    else:\n",
    "        return row['countries_en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100.0%"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    PROGRESS=0\n",
    "    size = df_1.shape[0]\n",
    "    df_1[result_column] = df_1.apply(lambda x: \n",
    "        translate_country(x,size),\n",
    "        axis = 1\n",
    "    )\n",
    "    saveTranslations()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/missing countries_en: 322\n",
      "Percentage of rows w/missing countries_en: 0.046%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/missing countries_en: {}\".format(len(df_1) - df_1[result_column].count()))\n",
    "print(\"Percentage of rows w/missing countries_en: {0:.3f}%\".format(100*(len(df_1)-df_1[result_column].count())/len(df_1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FOUND_MODULE:\n",
    "    # removing the columns that we no longer need\n",
    "    df_1 = df_1.drop(desired_columns, axis=1)\n",
    "\n",
    "    # drop rows without country\n",
    "    df_1 = df_1.dropna(subset=[result_column])\n",
    "\n",
    "    #saveModuleDF(result_column,df_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows w/multiple countries: 28626\n",
      "Number of total rows: 693524\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows w/multiple countries: {}\".format(len(df_1[df_1[result_column].str.contains(',')])))\n",
    "\n",
    "print(\"Number of total rows: {}\".format(len(df_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FOUND_MODULE:\n",
    "    # shows that some countries_en are lists\n",
    "    df_1[df_1[result_column].notnull() & df_1[result_column].str.contains(',')][result_column].head()\n",
    "\n",
    "\n",
    "    df_1[result_column] = df_1.apply(\n",
    "        lambda x: [x.strip() for x in x[result_column].split(',')],\n",
    "        axis = 1\n",
    "    )\n",
    "    #saveModuleDF(result_column,df_1)\n",
    "\n",
    "\n",
    "    # [x.strip() for x in my_string.split(',')]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>[France, United States]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            countries_values\n",
       "173  [France, United States]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows that the countries has been properly split\n",
    "df_1[df_1.index == 173][[result_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, this subsection deals with standardizing the countries for each product. First, we notice that some products have more than one country in their `countries_en` field. In this case, we seperate/explode each country in the `countries_en` field so that each country has its own row for that item. Next, we join the countries with their respective country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countries_values</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afghanistan</td>\n",
       "      <td>AF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>åland islands</td>\n",
       "      <td>AX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>albania</td>\n",
       "      <td>AL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>algeria</td>\n",
       "      <td>DZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american samoa</td>\n",
       "      <td>AS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  countries_values country_code\n",
       "0      afghanistan           AF\n",
       "1    åland islands           AX\n",
       "2          albania           AL\n",
       "3          algeria           DZ\n",
       "4   american samoa           AS"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the countries_en to country codes\n",
    "country_df = pd.read_csv(data_folder + countryfile, \n",
    "                         sep=',',\n",
    "                         header=0,\n",
    "                         usecols=['English short name lower case', 'Alpha-2 code'],\n",
    "                         quotechar='\"')\n",
    "# rename columns\n",
    "country_df.rename(columns={\n",
    "    'Alpha-2 code':'country_code',\n",
    "    'English short name lower case': result_column\n",
    "    }, inplace=True)\n",
    "\n",
    "country_df[result_column] = country_df.apply(\n",
    "    lambda x: x[result_column].lower(),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "country_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode(df, lst_cols, fill_value=''):\n",
    "    # make sure `lst_cols` is a list\n",
    "    if lst_cols and not isinstance(lst_cols, list):\n",
    "        lst_cols = [lst_cols]\n",
    "    # all columns except `lst_cols`\n",
    "    idx_cols = df.columns.difference(lst_cols)\n",
    "\n",
    "    # calculate lengths of lists\n",
    "    lens = df[lst_cols[0]].str.len()\n",
    "\n",
    "    if (lens > 0).all():\n",
    "        # ALL lists in cells aren't empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .loc[:, df.columns]\n",
    "    else:\n",
    "        # at least one list in cells is empty\n",
    "        return pd.DataFrame({\n",
    "            col:np.repeat(df[col].values, lens)\n",
    "            for col in idx_cols\n",
    "        }).assign(**{col:np.concatenate(df[col].values) for col in lst_cols}) \\\n",
    "          .append(df.loc[lens==0, idx_cols]).fillna(fill_value) \\\n",
    "          .loc[:, df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1.copy()\n",
    "\n",
    "if not FOUND_MODULE:\n",
    "    df_3 = explode(df_3,result_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>quantity</th>\n",
       "      <th>brands</th>\n",
       "      <th>brands_tags</th>\n",
       "      <th>categories</th>\n",
       "      <th>categories_tags</th>\n",
       "      <th>categories_en</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_tags</th>\n",
       "      <th>...</th>\n",
       "      <th>salt_100g</th>\n",
       "      <th>sodium_100g</th>\n",
       "      <th>alcohol_100g</th>\n",
       "      <th>calcium_100g</th>\n",
       "      <th>iron_100g</th>\n",
       "      <th>carbon-footprint_100g</th>\n",
       "      <th>nutrition-score-fr_100g</th>\n",
       "      <th>nutrition-score-uk_100g</th>\n",
       "      <th>glycemic-index_100g</th>\n",
       "      <th>countries_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Lion Peanut x2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_name generic_name quantity brands brands_tags categories  \\\n",
       "173  Lion Peanut x2          NaN      NaN    NaN         NaN        NaN   \n",
       "174  Lion Peanut x2          NaN      NaN    NaN         NaN        NaN   \n",
       "\n",
       "    categories_tags categories_en labels labels_tags       ...         \\\n",
       "173             NaN           NaN    NaN         NaN       ...          \n",
       "174             NaN           NaN    NaN         NaN       ...          \n",
       "\n",
       "    salt_100g sodium_100g alcohol_100g calcium_100g iron_100g  \\\n",
       "173       NaN         NaN          NaN          NaN       NaN   \n",
       "174       NaN         NaN          NaN          NaN       NaN   \n",
       "\n",
       "    carbon-footprint_100g nutrition-score-fr_100g  nutrition-score-uk_100g  \\\n",
       "173                   NaN                     NaN                      NaN   \n",
       "174                   NaN                     NaN                      NaN   \n",
       "\n",
       "    glycemic-index_100g countries_values  \n",
       "173                 NaN           France  \n",
       "174                 NaN    United States  \n",
       "\n",
       "[2 rows x 41 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how the explode function created another row because there were two countries for Lion Peanut x2\n",
    "df_3[df_3['product_name'].notna() & df_3['product_name'].str.contains('Lion Peanut x2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3[result_column] = df_3.apply(\n",
    "    lambda x: x[result_column].lower(),\n",
    "    axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to check the stats of the rows with a country_name but still without a country_code\n",
    "def notAssigned(df_sample):\n",
    "    not_assigned = df_sample[df_sample[result_column].notna() & df_sample['country_code'].isna()]\n",
    "\n",
    "    print(\"Number of unassigned items is: {}\".format(len(not_assigned)))\n",
    "    print(\"The important values are: \")\n",
    "    print(not_assigned[result_column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unassigned items is: 4566\n",
      "The important values are: \n",
      "russia                              2203\n",
      "en                                   477\n",
      "fr:deutschland                       229\n",
      "taiwan                               227\n",
      "vietnam                              107\n",
      "de:allemagne                          92\n",
      "ch:suisse                             82\n",
      "european union                        80\n",
      "south korea                           67\n",
      "fr:schweiz                            49\n",
      "republic of macedonia                 41\n",
      "fr:frankreich                         35\n",
      "categories completed                  34\n",
      "brands completed                      34\n",
      "product name completed                34\n",
      "packaging completed                   33\n",
      "characteristics completed             33\n",
      "ingredients completed                 33\n",
      "nutrition facts completed             33\n",
      "quantity completed                    33\n",
      "photos uploaded                       33\n",
      "photos validated                      30\n",
      "to be checked                         30\n",
      "complete                              30\n",
      "packaging-code-completed              26\n",
      "iran                                  24\n",
      "democratic republic of the congo      24\n",
      "fr:quebec                             24\n",
      "fr:dom-tom                            24\n",
      "republic of the congo                 21\n",
      "                                    ... \n",
      "de:belgique                            1\n",
      "plane                                  1\n",
      "ελλάδα                                 1\n",
      "luxemburgo                             1\n",
      "россия                                 1\n",
      "epernay                                1\n",
      "perth                                  1\n",
      "nutrition facts to be completed        1\n",
      "roumanie                               1\n",
      "photos to be uploaded                  1\n",
      "other-japon                            1\n",
      "champs fleurs                          1\n",
      "england                                1\n",
      "acapulco                               1\n",
      "bannans                                1\n",
      "dieppe france                          1\n",
      "fr:quebec-canada                       1\n",
      "washington                             1\n",
      "union européenne                       1\n",
      "guanajuato                             1\n",
      "united-states-of-america               1\n",
      "firenze                                1\n",
      "são paulo-sp brasil                    1\n",
      "w.i.                                   1\n",
      "quantity to be completed               1\n",
      "arménie                                1\n",
      "espagne                                1\n",
      "montréal                               1\n",
      "carib brewery ltd                      1\n",
      "guerrero                               1\n",
      "Name: countries_values, Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_5 = df_3.copy()\n",
    "\n",
    "if not FOUND_MODULE:\n",
    "    df_5 = df_5.merge(country_df, how='left')\n",
    "\n",
    "    notAssigned(df_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to fix the country codes with the highest frequency, since the importance/effect of fixing the lower values will decrease as we descend through the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing Russian Federation to russia\n",
    "country_df[result_column][country_df['country_code'] == 'RU'] = 'russia'\n",
    "\n",
    "# changing Korea, Republic of to south korea\n",
    "country_df[result_column][country_df['country_code'] == 'KR'] = 'south korea'\n",
    "\n",
    "# changing Macedonia, the former Yugoslav Republic of to republic of macedonia\n",
    "country_df[result_column][country_df['country_code'] == 'MK'] = 'republic of macedonia'\n",
    "\n",
    "# changing Taiwan, Province of China to taiwan\n",
    "country_df[result_column][country_df['country_code'] == 'TW'] = 'taiwan'\n",
    "\n",
    "# changing Viet Nam to vietnam\n",
    "country_df[result_column][country_df['country_code'] == 'VN'] = 'vietnam'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis of the unpaired countries, we see that a few countries are still in another language. Specifically, they are in the format \"language:country\". The method `parseTranslate` tries to deal with this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse and translate columns that are in the format \"language:value\"\n",
    "def parseTranslate(x, target_columns,size):\n",
    "    showProgress(size)\n",
    "    for column in target_columns:    \n",
    "        if (':') in x[column]:\n",
    "            info_ = x[column].split(':')\n",
    "            if len(info_) == 2:\n",
    "                value = info_[1]\n",
    "                return translateWithCache(value)\n",
    "        return x[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100.0%"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    PROGRESS=0\n",
    "    size=df_5.shape[0]\n",
    "    df_5[result_column] = df_5.apply(\n",
    "        lambda x: parseTranslate(x,[result_column],size),\n",
    "        axis = 1\n",
    "    )\n",
    "    saveTranslations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our description of the countries still missing country codes, it is found that most of these countries do not have the full name as the one in the CSV file `country_df`. Thus, we try to find the `best_match` and change the `country_name` in the food dataframe to match the one in the `country_df`. We consider something a `best_match` if the `country_name` from the food dataframe is a substring of the `country_name` in the country dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_5 = df_5.merge(country_df, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display result\n",
    "df_5[['product_name',result_column,'country_code']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match(country_df, row):\n",
    "    if pd.isnull(row['country_code']):\n",
    "        countries = list(country_df[result_column])\n",
    "        for country in countries:\n",
    "            if row[result_column] in country:\n",
    "                return country\n",
    "\n",
    "    return row[result_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unassigned items is: 928\n",
      "The important values are: \n",
      "suisse                                                                                         85\n",
      "european union                                                                                 80\n",
      "product name completed                                                                         34\n",
      "brands completed                                                                               34\n",
      "categories completed                                                                           34\n",
      "nutrition facts completed                                                                      33\n",
      "photos uploaded                                                                                33\n",
      "characteristics completed                                                                      33\n",
      "packaging completed                                                                            33\n",
      "ingredients completed                                                                          33\n",
      "quantity completed                                                                             33\n",
      "to be checked                                                                                  30\n",
      "complete                                                                                       30\n",
      "photos validated                                                                               30\n",
      "packaging-code-completed                                                                       26\n",
      "judgment-empty                                                                                 24\n",
      "democratic republic of the congo                                                               24\n",
      "quebec                                                                                         24\n",
      "kosovo                                                                                         23\n",
      "republic of the congo                                                                          21\n",
      "expiration date to be completed                                                                17\n",
      "expiration date completed                                                                      17\n",
      "gers                                                                                           15\n",
      "midi-pyrénées                                                                                  13\n",
      "danone produits frais france (dpff) - 2 avenue de l'industrie - 32730 villecomtal-sur-arros    13\n",
      "belgique                                                                                        9\n",
      "weil am rhein                                                                                   8\n",
      "méxico                                                                                          8\n",
      "palestinian territories                                                                         7\n",
      "world                                                                                           6\n",
      "                                                                                               ..\n",
      "republika srpska                                                                                1\n",
      "w.i.                                                                                            1\n",
      "quebec-canada                                                                                   1\n",
      "россия                                                                                          1\n",
      "california                                                                                      1\n",
      "san miguel de allende                                                                           1\n",
      "république dominicaine                                                                          1\n",
      "haute-normandie                                                                                 1\n",
      "u salumu                                                                                        1\n",
      "états-unis                                                                                      1\n",
      "dieppe france                                                                                   1\n",
      "virgin islands of the united states                                                             1\n",
      "pays-bas                                                                                        1\n",
      "münchen                                                                                         1\n",
      "gironde                                                                                         1\n",
      "lévis québec canada                                                                             1\n",
      "cluj-napoca                                                                                     1\n",
      "luxemburgo                                                                                      1\n",
      "epernay                                                                                         1\n",
      "acapulco                                                                                        1\n",
      "characteristics to be completed                                                                 1\n",
      "85220 l'aiguillon sur vie  france                                                               1\n",
      "frankfurt                                                                                       1\n",
      "perth                                                                                           1\n",
      "washington                                                                                      1\n",
      "navarra                                                                                         1\n",
      "nsw                                                                                             1\n",
      "nutrition facts to be completed                                                                 1\n",
      "united-states-of-america                                                                        1\n",
      "champs fleurs                                                                                   1\n",
      "Name: countries_values, Length: 105, dtype: int64\n",
      "Saved module: countries_values\n"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    df_5[result_column] = df_5.apply(\n",
    "        lambda x: best_match(country_df, x),\n",
    "        axis = 1\n",
    "    )\n",
    "    df_5 = df_5.drop(['country_code'], axis=1)\n",
    "\n",
    "    df_5 = df_5.merge(country_df, how='left')\n",
    "    notAssigned(df_5)\n",
    "    saveModuleDF(result_column,df_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with a country code: 724730\n",
      "Number of total rows: 693846\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of rows with a country code: {}\".format(len(df_5[df_5['country_code'].notna()])))\n",
    "print(\"Number of total rows: {}\".format(len(food_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of rows we can use (meaning the rows with a `country_code`) is higher than what we original started with because we made duplicates of some rows so that each country has its own instance of the item. An issue we ran into is that with the high number of translations we need to do, Google's API will eventually block our requests,thus some more rows might have actually been able to be paired up with a `country_code`. To try a walka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Nutrition Scores <a id=\"nutrition-scores\"></a>\n",
    "\n",
    "This section deals with NaN values for `nutrition score`.\n",
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in nutrition_grade_uk is 100.00%\n",
      "Percentage of NaN in nutrition_grade_fr is 79.79%\n",
      "Percentage of NaN in nutrition-score-fr_100g is 79.79%\n",
      "Percentage of NaN in nutrition-score-uk_100g is 79.79%\n"
     ]
    }
   ],
   "source": [
    "desired_columns=[\n",
    "    'nutrition_grade_uk',\n",
    "    'nutrition_grade_fr',\n",
    "    'nutrition-score-fr_100g',\n",
    "    'nutrition-score-uk_100g'\n",
    "]\n",
    "result_column='nutrition_score'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that `nutrition_grade_uk` is always nan and that `nutrition_grade_fr`, `nutrition-score-fr_100g` and `nutrition-score-uk_100g` have exactly the same value. For this reason, the column used is `nutrition_grade_fr`. Nan values are not filled since for now, the nutrition score is going to be an additional indicator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_df = food_df.copy()\n",
    "nutrition_df[result_column]=nutrition_df[desired_columns[1]] #.fillna(UNKNOWN_STR)\n",
    "nutrition_df = nutrition_df.drop(desired_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "Name: nutrition_score, dtype: object"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nutrition_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Allergens <a id=\"allergens\"></a>\n",
    "\n",
    "This section deals with NaN values for `allergens`.\n",
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in allergens_en is 100.00%\n",
      "Percentage of NaN in allergens is 90.07%\n"
     ]
    }
   ],
   "source": [
    "desired_columns=[\n",
    "    'allergens_en',\n",
    "    'allergens'\n",
    "]\n",
    "result_column='allergen_values'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allergen_values file not found\n",
      "Found module: False\n"
     ]
    }
   ],
   "source": [
    "allergen_df = getModuleDF(result_column)\n",
    "FOUND_MODULE = result_column in df.columns\n",
    "print(\"Found module: {}\".format(FOUND_MODULE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the result, both columns have different percentages, for some reason, values in `allergens_en` are urls so for further analysis only the `allergen` column is taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             allergens_en allergens\n",
      "264437  https://static.openfoodfacts.org/images/produc...   Dairies\n",
      "264467  https://static.openfoodfacts.org/images/produc...   Dairies\n",
      "264504  https://static.openfoodfacts.org/images/produc...   Dairies\n",
      "264510  https://static.openfoodfacts.org/images/produc...   Dairies\n",
      "264521  https://static.openfoodfacts.org/images/produc...   Dairies\n"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    print(allergen_df[allergen_df[desired_columns[0]].notna()][desired_columns].head(5))\n",
    "    allergen_df[result_column]=allergen_df[desired_columns[1]]\n",
    "    allergen_df1 = allergen_df.drop(desired_columns, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the allergens format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10                                   en:eggs,en:mustard\n",
       "22    BLÉ, GLUTEN, BLE, FROMAGE, LAIT, LAIT, LAIT, L...\n",
       "31            BLÉ, SEIGLE, BLÉ, SEIGLE, SAUMON, FROMAGE\n",
       "39                                              FROMAGE\n",
       "44     BLÉ, GLUTEN, BLE, BLE, ORGE, BLÉ, SÉSAME, SEIGLE\n",
       "Name: allergen_values, dtype: object"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allergen_notna_df=allergen_df1[allergen_df1[result_column].notna()].copy()\n",
    "allergen_notna_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing of the `result column` by assuring values are strings lowercase before processing.\n",
    "Using the helper function `formatAndTranslateRow`, allergen rows are going to be formated to an array and translated to english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 100.0%"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    allergen_notna_df[result_column].apply(str)\n",
    "    allergen_notna_df[result_column] = allergen_notna_df[result_column].apply(\n",
    "        lambda x: x.lower()\n",
    "    )\n",
    "    PROGRESS=0\n",
    "    allergen_notna_df[result_column] = allergen_notna_df[result_column].apply(\n",
    "        lambda x: formatAndTranslateRow(x,True)\n",
    "    )\n",
    "    saveTranslations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10                                   [eneggs, enmustard]\n",
       "22     [became, gluten, became, cheese, milk, milk, m...\n",
       "31            [became, rye, became, rye, salmon, cheese]\n",
       "39                                              [cheese]\n",
       "44     [became, gluten, became, became, barley, becam...\n",
       "46                                    [eneggs, engluten]\n",
       "282                                                [soy]\n",
       "293                     [became, butter, eggs, hazelnut]\n",
       "315                                   [almonds, almonds]\n",
       "342                                     [milk, hazelnut]\n",
       "Name: allergen_values, dtype: object"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(allergen_notna_df.shape[0])\n",
    "allergen_notna_df[allergen_notna_df[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FOUND_MODULE:\n",
    "    allergen_df1_=allergen_df1.rename(columns = {result_column:'old_values'})['old_values']\n",
    "    allergen_df1[result_column]=pd.concat([allergen_df1_, allergen_notna_df], axis=1, join_axes=[allergen_df1.index])[result_column]           \n",
    "    saveModuleDF(result_column,allergen_df1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693846, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10                                   [eneggs, enmustard]\n",
       "22     [became, gluten, became, cheese, milk, milk, m...\n",
       "31            [became, rye, became, rye, salmon, cheese]\n",
       "39                                              [cheese]\n",
       "44     [became, gluten, became, became, barley, becam...\n",
       "46                                    [eneggs, engluten]\n",
       "282                                                [soy]\n",
       "293                     [became, butter, eggs, hazelnut]\n",
       "315                                   [almonds, almonds]\n",
       "342                                     [milk, hazelnut]\n",
       "Name: allergen_values, dtype: object"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(allergen_df1.shape)\n",
    "allergen_df1[allergen_df1[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in allergen_values is 90.07%\n"
     ]
    }
   ],
   "source": [
    "showNanPercentage(allergen_df1,[result_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill in Missing Traces <a id=\"traces\"></a>\n",
    "\n",
    "This section deals with NaN values for `traces`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in traces_en is 91.46%\n",
      "Percentage of NaN in traces is 93.22%\n"
     ]
    }
   ],
   "source": [
    "desired_columns=[\n",
    "    'traces_en',\n",
    "    'traces'\n",
    "]\n",
    "result_column='traces_values'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "traces_values file not found\n",
      "Found module: False\n"
     ]
    }
   ],
   "source": [
    "traces_df = getModuleDF(result_column)\n",
    "FOUND_MODULE = result_column in df.columns\n",
    "print(\"Found module: {}\".format(FOUND_MODULE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not FOUND_MODULE:\n",
    "    traces_df1=mergeColumnsFromDF(traces_df, desired_columns, result_column)\n",
    "    \n",
    "traces_notna_df=traces_df1[traces_df1[result_column].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in traces_values is 91.46%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111                                            Eggs,Milk\n",
       "129                                         Sesame seeds\n",
       "220    Eggs,Gluten,Milk,Nuts,Soybeans,Oatmeal,Wheatflour\n",
       "255    fr:contient-oeuf-lait-anchois-soya-ble-seigle-...\n",
       "275    Soybeans,Sulphur dioxide and sulphites,fr:cont...\n",
       "Name: traces_values, dtype: object"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showNanPercentage(traces_df1,[result_column])\n",
    "traces_notna_df[result_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 86.0%"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    PROGRESS=0\n",
    "    traces_notna_df[result_column] = traces_notna_df[result_column].apply(\n",
    "        lambda x: formatAndTranslateRow(x,False)\n",
    "    )\n",
    "    saveTranslations()\n",
    "    #saveModuleDF(result_column,traces_notna_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59252, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "111                                         [eggs, milk]\n",
       "129                                       [sesame seeds]\n",
       "220    [eggs, gluten, milk, nuts, soybeans, oatmeal, ...\n",
       "255    [frcontientoeuflaitanchoissoyableseigleorgemou...\n",
       "275    [soybeans, sulphur dioxide and sulphites, frco...\n",
       "286    [gluten, frpeutcontenirnoixvariessoyalaitoeufs...\n",
       "293                       [nuts, sesame seeds, soybeans]\n",
       "299    [celery, crustaceans, eggs, fish, gluten, milk...\n",
       "300                                               [eggs]\n",
       "306    [eggs, gluten, milk, mustard, nuts, sesame see...\n",
       "Name: traces_values, dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(traces_notna_df.shape)\n",
    "traces_notna_df[traces_notna_df[result_column].notna()][result_column].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved module: traces_values\n"
     ]
    }
   ],
   "source": [
    "if not FOUND_MODULE:\n",
    "    traces_df1_=traces_df1.rename(columns = {result_column:'old_values'})['old_values']\n",
    "    traces_df1[result_column]=pd.concat([traces_df1_, traces_df1], axis=1, join_axes=[traces_df1.index])[result_column]           \n",
    "    saveModuleDF(result_column,traces_df1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693846, 45)\n",
      "Percentage of NaN in traces_values is 91.46%\n"
     ]
    }
   ],
   "source": [
    "print(traces_df1.shape)\n",
    "traces_df1[traces_df1[result_column].notna()][result_column].head(10)\n",
    "showNanPercentage(traces_df1,[result_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill/Clean Ingredients <a id=\"ingredients\"></a>\n",
    "This section deals with NaN values for `ingredients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN in ingredients_text is 43.30%\n"
     ]
    }
   ],
   "source": [
    "desired_columns=[\n",
    "    'ingredients_text'\n",
    "]\n",
    "result_column='ingredients_values'\n",
    "showNanPercentage(food_df,desired_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with the analysis let's show the percentage of nan values in the desired columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingredients_values file not found\n",
      "Found module: False\n"
     ]
    }
   ],
   "source": [
    "ingredients_df = getModuleDF(result_column)\n",
    "FOUND_MODULE = result_column in ingredients_df.columns\n",
    "print(\"Found module: {}\".format(FOUND_MODULE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the format of each ingredient entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ingredients_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>antioxydant : érythorbate de sodium, colorant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lait entier, sucre, amidon de maïs, cacao, Aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>baguette Poite vin Pain baguette 50,6%: fqrine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Paln suédois 42,6%: farine de BLÉ, eau, farine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Taboulé 76,2%, légumes 12%, huile de colza, se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ingredients_text\n",
       "10  antioxydant : érythorbate de sodium, colorant ...\n",
       "15  Lait entier, sucre, amidon de maïs, cacao, Aga...\n",
       "22  baguette Poite vin Pain baguette 50,6%: fqrine...\n",
       "31  Paln suédois 42,6%: farine de BLÉ, eau, farine...\n",
       "33  Taboulé 76,2%, légumes 12%, huile de colza, se..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_df[ingredients_df[desired_columns[0]].notna()][desired_columns].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredients_df=ingredients_df.rename(columns={desired_columns[0]:result_column})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeCommonWords(value):\n",
    "    words=['long','grain','white','refined','concentrate','natural','dry','roasted','organic','bar','whole','rolled','seasoning','juice','extract']\n",
    "    value_=value\n",
    "    for word in words:\n",
    "        if word in value_:\n",
    "            value_=value_.replace(word,\"\")\n",
    "    return normalizeString(value_)\n",
    "\n",
    "def cleanIngredients(row):\n",
    "    showProgress(ingredients_df.shape[0])\n",
    "    if type(row) is not list and pd.notnull(row) :\n",
    "        values=row.split(',')\n",
    "        ingredients=[]\n",
    "        for item in values:\n",
    "            ingredient=item\n",
    "            # format key:value\n",
    "            # take only value\n",
    "            if (':') in ingredient:\n",
    "                info_ = ingredient.split(':')\n",
    "                if len(info_) == 2:\n",
    "                    ingredient=info_[1]\n",
    "            # format value (info)\n",
    "            # take only values\n",
    "            if ('(') in ingredient:\n",
    "                info_ = ingredient.split('(')\n",
    "                ingredient=info_[0]\n",
    "                \n",
    "            # format value [value,...]\n",
    "            # take all values\n",
    "            if ('[') in ingredient:\n",
    "                info_ = ingredient.split('[')\n",
    "                if len(info_) >= 2:\n",
    "                    ingredients.append(removeCommonWords(normalizeString(info_[0])))\n",
    "                    ingredient=info_[1]\n",
    "            # format value [value,...]\n",
    "            # take all values\n",
    "            if (' or ') in ingredient:\n",
    "                info_ = ingredient.split('or')\n",
    "                if len(info_) >= 2:\n",
    "                    ingredients.append(removeCommonWords(normalizeString(info_[0])))\n",
    "                    ingredient=info_[1]\n",
    "            # format value - info\n",
    "            # take only values\n",
    "            if (' - ') in ingredient:\n",
    "                info_ = ingredient.split('-')\n",
    "                ingredient=info_[0]\n",
    "                \n",
    "            # avoid empty strings and removeCommonWords\n",
    "            ingredient=removeCommonWords(normalizeString(ingredient))\n",
    "            if ingredient:\n",
    "                ingredient_trans=translateWithCache(ingredient) \n",
    "                ingredients.append(ingredient_trans)\n",
    "        \n",
    "        # remove duplicate elements\n",
    "        ingredients_=removeDuplcates(ingredients)\n",
    "        return ingredients_\n",
    "    else:\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress 0.0%Exception erythorbate de sodium / <class 'str'> / list index out of range\n",
      "Exception jaunes doeuf / <class 'str'> / list index out of range\n",
      "Exception es de moutarde / <class 'str'> / list index out of range\n",
      "Exception dextrose / <class 'str'> / list index out of range\n",
      "Exception gomme de cellulose / <class 'str'> / list index out of range\n",
      "Exception sorbate de potassium / <class 'str'> / list index out of range\n",
      "Exception carotene / <class 'str'> / list index out of range\n",
      "Exception arome / <class 'str'> / list index out of range\n",
      "Progress 0.0%"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-40bd66f7e1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mPROGRESS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ingredients_notna_df[result_column] = ingredients_notna_df[result_column].apply(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcleanIngredients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     \u001b[0msaveTranslations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/ada/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-48-40bd66f7e1eb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mPROGRESS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ingredients_notna_df[result_column] = ingredients_notna_df[result_column].apply(\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcleanIngredients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     )\n\u001b[1;32m      7\u001b[0m     \u001b[0msaveTranslations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-cd2f6e9711e7>\u001b[0m in \u001b[0;36mcleanIngredients\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mingredient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremoveCommonWords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalizeString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mingredient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mingredient_trans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranslateWithCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mingredients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mingredient_trans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-b521c1c03c3e>\u001b[0m in \u001b[0;36mtranslateWithCache\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRANSLATION_DELAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mtrns_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrns_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ingredients_notna_df=ingredients_df[ingredients_df[result_column].notna()]\n",
    "if not FOUND_MODULE:\n",
    "    PROGRESS=0\n",
    "    ingredients_notna_df[result_column] = ingredients_notna_df[result_column].apply(\n",
    "        lambda x: cleanIngredients(x)\n",
    "    )\n",
    "    saveTranslations()\n",
    "    saveModuleDF(result_column,ingredients_notna_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"antioxydant : érythorbate de sodium, colorant : caramel - origine UE), tomate 33,3%, MAYONNAISE 11,1% (huile de colza 78,9%, eau, jaunes d'OEUF 6%, vinaigre, MOUTARDE [eau, graines de MOUTARDE, sel, vinaigre, curcuma], sel, dextrose, stabilisateur : gomme de cellulose, conservateur : sorbate de potassium, colorant : ?-carotène, arôme)\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingredients_notna_df[result_column][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill/Clean Labels <a id=\"labels_column\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean float64 Columns <a id=\"float64_col\"></a>\n",
    "Karen's part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization & Analysis <a id=\"data_analysis\"></a>\n",
    "TO BE COMPLETED FOR MILESTONE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTranslations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations b/w Neighbouring Countries <a id=\"correlation_neighbours\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
